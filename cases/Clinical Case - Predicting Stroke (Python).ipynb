{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p align=\"justify\">Welcome! In this case we'll be exploring how to use advanced analytic and machine learning techniques to predict strokes. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Some of the skills you'll explore are (Click to Expand):</summary>\n",
    "<ul>\n",
    "    <li>R Programming</li>\n",
    "    <li>Data Cleaning</li>\n",
    "    <li>Exploratory Data Analysis</li>\n",
    "    <li>Data Visualization</li>\n",
    "    <li>Leveraging Domain Knowledge</li>\n",
    "    <li>Machine Learning</li>\n",
    "    <li>Random Forest Algorithm</li>\n",
    "</details><br>\n",
    "Don't worry if you're unsure what some of these terms are. They'll be explained throughout the case. Let's begin! \n",
    "\n",
    "<img src=\"https://www.fromthegenesis.com/wp-content/uploads/2018/06/RanFore.jpg\" style=\"float: left; width: 34%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSxzj-rl3NFqS8Iow-h_3cE2mJoINBs9ZFOjo-tx44d86KiRja7\" style=\"float: left; width: 33%; margin-left: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://www.edvancer.in/wp-content/uploads/2015/10/f5bd5f87059fce20564f6e5eb562022e.png\" style=\"float: left; width: 27%; margin-left: 1%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Case Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine you're an emergency physician at a local community hospital. Your hospital has recently joined a regional initiative to improve quality of care for stroke. After undergoing over a decade of training, you're well-versed in the clinical manifestations of stroke. Still, you know there is great uncertainty in diagnosing and treating stroke. The window for treatment is narrow and the drugs involved can have dangerous side-effects. Can analytics and machine learning help with this uncertainty?\n",
    "\n",
    "Continue the case to find out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clinical Background: Stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Stroke is an acute neurologic condition referred to as a cerebrovascular event. This means stroke is a condition that affects the brain (\"cerebro-\") and involves blood vessels (\"vascular). In stroke, arteries leading to and within the brain are either blocked by a clot or rupture. The end result is lack of oxygen and nutrients to the brain leading to brain damage. \n",
    "\n",
    "<center>\n",
    "  <img width=\"500\" height=300 src=\"https://www.strokeinfo.org/wp-content/uploads/2019/06/HTN_16_pg39_art600x400.png\">\n",
    "<\\center>\n",
    "\n",
    "Stroke is usually diagnosed clinically (by symptoms) and imaging (non-contrast head CT scan). Stroke can exhibit a wide range of symptoms depending on the location affected within the brain. Some nonspecific symptoms include headache (\"worst headache of my life\", nausea, vomiting, loss of consciousness, and neck stiffness. If suspected a non-contrast head CT is ordered to detect bleeding. Depending on whether the stroke is caused by a clot or rupture, treatment will be different. A clot will be treated with blood thinners. A rupture will be treated through emergent neurosurgery. \n",
    "\n",
    "> Stroke require prompt diagnosis and treatment before irreversible damages sets in. Any tool (such as a predictive model) that could make stroke diagnosis quicker or easier could make a large difference in preventing stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using Jupyter Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To run any of the code, select the code cell on the **bottom right (1.2)**, and click the `Run` button on the toolbar above. Try it out on the example code cell below on the **bottom right (1.2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "source": [
    "**The** `Run` **Button**\n",
    "<img src=\"https://i.imgur.com/jr4dpLW.png\" style=\"width:300px;height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T15:06:39.581180Z",
     "start_time": "2019-11-06T15:06:39.577152Z"
    },
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is an example of a code cell\n",
    "print('Congratulations!')\n",
    "print('You\\'ve run your first code cell.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Jupyter Notebook Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is a Jupyter Notebook? Why is it so special? Below is a definition of Jupyter Notebook from the creators. \n",
    "\n",
    "> \"The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\" - [jupyter.org](https://www.jupyter.org)\n",
    "\n",
    "Through integrating code, text, and multimedia, jupyter notebooks allow us to create a digital notebook that is both **interactive** and **informative**. Don't just take my word for it though, personally explore how Jupyter Notebook can augment your learning through the case!\n",
    "\n",
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/1-LPnY8nOLg4S6_TG0DEXwsg-1.png\" style=\"width:600px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Case Code Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Within code cells you will see green text preceded by a `#` symbol. These are comments and will help explain what portions of the code are doing. All code should be ready to run as shown. \n",
    "\n",
    "Some code may require more time to run. On the left hand side you will notice the label: `In [ ]:`. If there is an `*` in between the `[]`'s after you select `Run`, that indicates that your code is in the process of running. Like so: `In [*]:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Meeting Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll be using a deidentified set of patient data made available on [kaggle](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1), a data science community website. The data was originally provided by Mckinsey Analytics for a online hackathon hosted by Analytics Vidhya.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p style=\"text-align: center;\">stroke_predict.csv</p>\n",
    "\n",
    "***\n",
    "This file contains our dataset. There are a little over 43,000 patients with 12 variables. The data includes general demographic and clinical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset will already be downloaded for the case. The The original data can be acceded [here](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Consulting the Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are several variables or labels which you might not understand. There are many reasons for this. You might lack domain experience for the data you're analyzing. The data creators might also have used arbitrary labels only they understood (this is considered a bad practice).\n",
    "\n",
    "The way to combat this is by consulting the data dictionary or documentation. These are tables or documents which describe the data in detail. Have a variable you don't understand? Check the documentation! Don't understand what an output for a variable means? Check the documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A data dictionary is provided on the [kaggle page](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1#Screen%20Shot%202018-04-17%20at%2012.15.42%20AM.png) where the data is hosted. The data dictionary has also been reproduced below for your convenience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Variable*        | *Definition*                                           |\n",
    "| ----------------- | ------------------------------------------------------ |\n",
    "| id                | Patient ID                                             |\n",
    "| gender            | Gender of Patient                                      |\n",
    "| age               | Age of Patient                                         | \n",
    "| hypertension      | 0 - no hypertension, 1 - suffering from hypertension   |\n",
    "| heart_disease     | 0 - no heart disease, 1 - suffering from heart disease |\n",
    "| ever_married      | Yes/No                                                 |\n",
    "| work_type         | Type of occupation                                     |\n",
    "| Residence_type    | Area type of residence (Urban/ Rural                   |\n",
    "| avg_glucose_level | Average Glucose level (measured after meal)            |\n",
    "| bmi               | Body mass index                                        |\n",
    "| smoking_status    | patient's smoking status                               |\n",
    "| stroke            | patient's smoking status                               |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup (Do Not Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the code below to set up specific settings for our case. Do not skip this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:06.438017Z",
     "start_time": "2019-11-05T19:35:04.079942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calling external libraries for additional functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "from pandas.api.types import CategoricalDtype \n",
    "plt.style.use('fivethirtyeight')\n",
    "# Increase max number of columns displayed in output tables\n",
    "pd.set_option(\"display.max_columns\",2000)\n",
    "\n",
    "# Make sure your ML results are the same\n",
    "random.seed(10)\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cleaning Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first step in any analytic project is to clean our data. This is a critical step that is commonly overlooked within data science projects. This is critical for making our data convenient to interpret and manipulate. In addition, many analytic techniques require properly formatted data. Finally, healthcare datasets may have have data that isn't clinically relevant (ie. raw lab values). Processing can convert these variables into clinically meaningful information. It won't matter how sophisticated our analysis is if we don't properly process our data. A common saying in data science is \"Junk in, Junk out\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Reading Our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll begin by reading in our data so we can clean and use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:16.233699Z",
     "start_time": "2019-11-05T19:35:16.110928Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note: Unicode Transformation Format – 8 (UTF-8) is a standard to encode characters in different languages\n",
    "print('Data loading, please wait')\n",
    "stroke_data = pd.read_csv(\"data/stroke_predict.csv\",  encoding=\"UTF-8\" ,sep=\",\")\n",
    "print('Data loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's get an overview of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:18.279811Z",
     "start_time": "2019-11-05T19:35:18.253707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that many variables have not been coded into an easily human-readable format (ie. `hypertension`, `heart_disease`, `stroke`). We will also need to convert some of the clinical variables into meaningful categories (`avg_glucose_level` and `bmi`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Recoding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our first task will be recoding the variables `hypertension` (high blood pressure), `heart_disease`, and `stroke` into something meaningful. Based upon the data dictionary, we can see that a value of `1` for any of these fields indicates the patient is suffering from this condition. A value of `0` indicates they are not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:22.109737Z",
     "start_time": "2019-11-05T19:35:21.941568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Recoding\n",
    "stroke_data.loc[stroke_data['hypertension']==1,'hypertension'] = 'History of hypertension'\n",
    "stroke_data.loc[stroke_data['hypertension']==0,'hypertension'] = 'No hypertension'\n",
    "stroke_data.loc[stroke_data['heart_disease']==1,'heart_disease'] = 'History of heart disease'\n",
    "stroke_data.loc[stroke_data['heart_disease']==0,'heart_disease'] = 'No heart disease'\n",
    "stroke_data.loc[stroke_data['stroke']==1,'stroke'] = 'History of stroke'\n",
    "stroke_data.loc[stroke_data['stroke']==0,'stroke']='No stroke'\n",
    "\n",
    "print('Data Recoded')\n",
    "stroke_data[['hypertension','heart_disease','stroke']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:25.688488Z",
     "start_time": "2019-11-05T19:35:25.669338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data[['hypertension','heart_disease','stroke']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks like our changes were successful. In the output, notice the `int`. This is R's way to tell us that R considers these a integer variable. For our purposes, we can consider integers as a subtype of numeric variables. \n",
    "\n",
    "We will be converting these into categorical variables since these variables have a limited number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is the difference between a numeric and categorical variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "- **Numeric:** variables whose values are whole numbers (ie. numbers, percents)\n",
    "- **Categorical:** variables whose values are selected from a group (ie. dog breeds, male/female) \n",
    "\n",
    "> Note R calls categorical variables **Factors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:28.820121Z",
     "start_time": "2019-11-05T19:35:28.800796Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.hypertension.astype('category')\n",
    "stroke_data.heart_disease.astype('category')\n",
    "stroke_data.stroke.astype('category')\n",
    "\n",
    "print('Conversion complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let examine our data for missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:31.448387Z",
     "start_time": "2019-11-05T19:35:31.406112Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Number of Missing Data for Each Variable:')\n",
    "stroke_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Besides `bmi` our data looks exceptionally clean. This rarely happens. It is more likely that our data is not coded correctly. Lets examine our data more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:34.185276Z",
     "start_time": "2019-11-05T19:35:34.160921Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that `smoking_status` has numerous NaN. Lets take a closer look at `smoking_status`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:36.578212Z",
     "start_time": "2019-11-05T19:35:36.560269Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.smoking_status.value_counts()\n",
    "print('The number of missing values:' ,stroke_data.smoking_status.isnull().sum())\n",
    "stroke_data.smoking_status.fillna('never smoked',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Checking for Implausible Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets check our data for implausible values. Focus on the minimum and maximum values for the output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:38.973804Z",
     "start_time": "2019-11-05T19:35:38.905276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# numerical variables\n",
    "stroke_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:41.987475Z",
     "start_time": "2019-11-05T19:35:41.947416Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categorical variables\n",
    "stroke_data.gender.value_counts()\n",
    "stroke_data.hypertension.value_counts()\n",
    "stroke_data.heart_disease.value_counts()\n",
    "stroke_data.work_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:42.573950Z",
     "start_time": "2019-11-05T19:35:42.538000Z"
    },
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.ever_married.value_counts()\n",
    "stroke_data.Residence_type.value_counts()\n",
    "stroke_data.smoking_status.value_counts()\n",
    "stroke_data.stroke.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Among our variables, we can see that `bmi` has a maximum 97.60. It biologically unlikely for an individual to have a `bmi` of 97.60. Lets take a closer look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:44.945402Z",
     "start_time": "2019-11-05T19:35:44.929085Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('BMI:')\n",
    "stroke_data.bmi.quantile((0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that the the max `bmi` is a huge jump even compared to our 99th percentile. However, a `bmi` of 10.1, while underweight, is physiologically possible. Based on our finding, lets reclassify implausible values as `Na`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:47.339810Z",
     "start_time": "2019-11-05T19:35:47.329005Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.loc[stroke_data.bmi > 60, 'bmi'] = np.nan\n",
    "print('Values Reclassified!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Creating Clinically Relevant Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our data includes two clinical measures: `avg_glucose_lvl` and `bmi`. As raw values, these variables are not optimal for providing clinical information. Adding context can help with this.\n",
    "\n",
    "We will be taking these measures and creating clinically meaningful variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI stands for Body Mass Index. This a measure of body weight based upon a person's weight and height. This measure is commonly used to evaluate whether a person is overweight. Below is the BMI formula. \n",
    "\n",
    "\\[\\large \\frac{weight (kg)}{[height (m)]^{2}}\\]\n",
    "\n",
    "We will create a new variable which reflects the clinical cutoffs for bmi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the clinical cut-offs for BMI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *BMI Range*     |\n",
    "| -------------- | --------------- |\n",
    "| Underweight    | BMI < 18.5      |\n",
    "| Healthy Weight | 18.5 ≤ BMI < 25 |\n",
    "| Overweight     | 25 ≤ BMI < 30   |\n",
    "| Obese          | 30 ≥ BMI        |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let create the new variable `bmi_interp` based off these cut-offs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:50.033269Z",
     "start_time": "2019-11-05T19:35:49.980587Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create 'bmi_interp'\n",
    "stroke_data.dropna(subset=['bmi'],inplace=True)\n",
    "stroke_data['bmi_interp'] = stroke_data.bmi.apply(lambda x: 'Underweight' if x < 18.5 \n",
    "                                                  else ('Health Weight' if x>=18.5 and x<25 \n",
    "                                                        else ('Overweight' if x>=25 and x<30 \n",
    "                                                              else 'Obese' )) )\n",
    "\n",
    "\n",
    "# Convert from character to categorical\n",
    "# Make sure is ordered\n",
    "stroke_data.bmi_interp=stroke_data.bmi_interp.astype(CategoricalDtype(categories=['Underweight', 'Health Weight',\n",
    "                                                                    'Overweight', 'Obese'], ordered=True))\n",
    "\n",
    "print('\\'bmi_interp\\' variable created!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:35:53.554434Z",
     "start_time": "2019-11-05T19:35:53.532222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data[['bmi','bmi_interp']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Limitations and Considerations when using BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI is a simple, inexpensive, and common measure for body fat. However, there are several clinical considerations to keep in mind when using this measure. It's critical to keep in mind BMI is only a surrogate measure since it uses weight instead of actual body fat content in its calculations. Below are three examples of factors that can influence BMI:\n",
    "\n",
    "- Age: older adults usually have more body fat than younger adults for the same BMI\n",
    "- Gender: women tend to have greater amounts of body fat compared to men for the same BMI\n",
    "- Muscle mass: muscular individuals or athletes may have higher BMI due to increased muscle mass\n",
    "\n",
    "[Source](https://www.cdc.gov/obesity/downloads/bmiforpactitioners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Average Glucose Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The data dictionary defines `avg_glucose_lvl` as the average glucose level measured after meals (glucose is another term for blood sugar levels). Glucose levels are commonly used to assess whether a patient has diabetes. A patient with diabetes will have on-average a higher blood glucose level.\n",
    "\n",
    "However, `avg_glucose_lvl`, as defined by the data dictionary, is clinically problematic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Food for Thought:** What's wrong with 'avg_glucose_lvl' as a measure of blood glucose levels? What is a better measure of average blood sugar status?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Individual's blood glucose can vary widely day to day. This is especially true after meals when individuals are experiencing a physiological spike in their glucose levels. \n",
    "\n",
    "[Here's a news article discussing inter-population variability in glucose measurements](https://www.medicalnewstoday.com/articles/322614.php)\n",
    "\n",
    "A better measure would be hemoglobin A1C which measures the amount of sugar attached to each red blood cell. This is an indication of the average blood glucose status of a patient over 2 to 3 months. \n",
    "\n",
    "<img src=\"https://www.ekfdiagnostics.com/res/HbA1c-Hemoglobin-banner\" style=\"text-align: center; width: 66%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can't change the measurements used in the data. However, just because the glucose measurement is not ideal doesn't mean we need to disregard it completely. Every bit of data counts in analytics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A good proxy for `avg_glucose_level` would be the cutoffs determined by the oral glucose tolerance test (OGTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the criteria for normal, prediabetic, and diabetic in the OGTT two hours after drinking??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *Blood Glucose (mg/dl)*   |\n",
    "| -------------- | ------------------------- |\n",
    "| Diabetic       | 200 ≤ Blood Glucose       |\n",
    "| Prediabetic    | 140 ≤ Blood Glucose < 200 |\n",
    "| Healthy        |  Blood Glucose < 140      |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now use these criteria to classify a patient's 'avg_glucose_level' as either normal, prediabetic, or diabetic based upon OGTT criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:00.635263Z",
     "start_time": "2019-11-05T19:36:00.603696Z"
    },
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Create 'diabetic_interp'\n",
    "stroke_data['diabetic_interp'] = stroke_data.avg_glucose_level.apply(lambda x: 'Healthy' if x < 140 \n",
    "                                                  else ('Prediabetic' if x>=140 and x<200\n",
    "                                                              else 'Diabetic')) \n",
    "\n",
    "\n",
    "# Convert from character to categorical\n",
    "stroke_data.diabetic_interp=stroke_data.diabetic_interp.astype(CategoricalDtype(categories=['Healthy', 'Prediabetic',\n",
    "                                                                    'Diabetic'], ordered=True))\n",
    "\n",
    "print('\\'diabetic_interp\\' variable created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:03.552060Z",
     "start_time": "2019-11-05T19:36:03.537605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data[['avg_glucose_level','diabetic_interp']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've cleaned our data we can begin exploring our data. Using this, we can see which features are good candidates for building our prediction model. Feature selection  will determine how good or how bad your model is. Bad feature selection can have a hugely negative impact on your model even if you used the most advanced techniques. Understanding the clinical nuances of your data can inform better feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Why Can't We Just Use All or Most Variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One issue you might be wondering about is why do we even need to select variables. Why not just use all of the variables? After all, more data lead to better models right? This is a common misconception that even experienced analysts need to watch out for. Including too many features in your prediction model can lead to what is known as **overfitting**.\n",
    "\n",
    "<img src=\"https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1527613915658.png\" align=\"center\" style=\"width: 50%; margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    " **Overfitting** is essentially where you build a model that adheres too closely to your current data set and is unable to predict observations that are not from your current data set. In other words, its where you develop a model that tuned too closely to your current data, and is not generalizable to outside data sources. A prediction model that is not generalizeable is not a useful model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Getting A Closer Look At Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets take a closer look as we begin our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:14.758661Z",
     "start_time": "2019-11-05T19:36:14.731947Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:15.510082Z",
     "start_time": "2019-11-05T19:36:15.465545Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:17.611067Z",
     "start_time": "2019-11-05T19:36:17.561850Z"
    },
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.gender.value_counts()\n",
    "stroke_data.hypertension.value_counts()\n",
    "stroke_data.heart_disease.value_counts()\n",
    "stroke_data.ever_married.value_counts()\n",
    "stroke_data.work_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:17.743717Z",
     "start_time": "2019-11-05T19:36:17.707709Z"
    },
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.Residence_type.value_counts()\n",
    "stroke_data.smoking_status.value_counts()\n",
    "stroke_data.stroke.value_counts()\n",
    "stroke_data.bmi_interp.value_counts()\n",
    "stroke_data.diabetic_interp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This summary page presents us with quite a bit of data. The first thing to realize is that the output will differ based on whether the variable is numeric or categorical. Numeric outputs will include summary statistics while categorical variables will include frequency counts of each category. \n",
    "\n",
    "These summaries will provide a useful reference throughout our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Missing data can bias the results of our analysis. For instance, say that the individuals that did not respond about smoking status refused to respond because they were embarrassed of their smoking habit. This might make smoking individuals more likely to be smokers compared to individuals that responded to the survey. \n",
    "\n",
    "In summary, missing data can be problematic, especially if the missing group is somehow different from the non-missing group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "A chi-square test is a statistical test that tells you whether groups of observations are different. For instance, say you're researching two companies and you divide them either as male or female. The number of males compared to females in the two companies differ but how can you tell that this is not random chance? A chi-squared test can be used to differentiate whether the **observed** number of males and females in your study differs from the **expected** number of males and females. \n",
    "\n",
    "> Note: Chi-square tests can only be used for categorical variables. There are seperate tests to determine whether numerical numbers differ form one another. These additional tests are beyond the scope of the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Assessing Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets take a look at our other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:26.731018Z",
     "start_time": "2019-11-05T19:36:26.680141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that there are a couple numeric variables. However, the only one we would consider is age since the `bmi` and `avg_glucose_level` have newer and more clinically relevant variables available. \n",
    "\n",
    "We have some summary stats about age available. Lets take a look at the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:47:52.773348Z",
     "start_time": "2019-11-05T19:47:52.282369Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Plot\n",
    "plt.figure(figsize=(15,15))\n",
    "n, bins, patches=plt.hist(stroke_data.age,bins='auto', alpha=0.7, rwidth=0.85)\n",
    "xlabel=plt.xlabel('Age (years)')\n",
    "ylabel=plt.ylabel('Frequency Count')\n",
    "plt.axvline(stroke_data.age.median(), color='r',linestyle='dashed')\n",
    "plt.text(45,1500,'Dashed Line Represents Median Age (44 Years)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There does not appear to be any extreme age values or prominent age clusters. Now lets see if theres a relationship between stroke status and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:49:03.583701Z",
     "start_time": "2019-11-05T19:49:02.959754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.violinplot(y=stroke_data.stroke,x=stroke_data.age,orient='h')\n",
    "print('The dots in the center of each violin plot represent median age of each group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The results are pretty stark. Both median age and distribution of age drastically differs between the stroke and non-stroke group. This make sense since as individuals age, they are predisposed to cardiovascular events such as atherosclerosis or stroke. \n",
    "\n",
    "These results indicate age is an excellent candidate variable for our model since age seems to have a large effect on stroke status. This indicates our model could use age to differente between stroke and no stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally lets look at our remaining variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The rest of the variable of interest are categorical. We should be able to observe their effect on stroke well and quickly using stacked bar plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:36:35.254439Z",
     "start_time": "2019-11-05T19:36:35.227040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:51:07.766648Z",
     "start_time": "2019-11-05T19:51:07.750482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def stacked_plot(feature):\n",
    "    binary=stroke_data.groupby('stroke')\n",
    "    length=len(stroke_data[feature].unique())\n",
    "    layers=[]\n",
    "    for symbol, group in binary:\n",
    "        sequence=group[feature].value_counts().index\n",
    "        temp=[]\n",
    "        try:\n",
    "            for i in range(length):\n",
    "                number=group[feature].value_counts()[i]\n",
    "                temp.append(number)\n",
    "        except:\n",
    "            print('there\\'s no case for at least one category ')\n",
    "        temp=dict(zip(sequence,temp))\n",
    "        layers.append(temp)\n",
    "    names=stroke_data[feature].unique()\n",
    "    no_stroke_layer=[0]*len(names)\n",
    "    stroke_layer=[0]*len(names)\n",
    "    position=np.arange(len(names))+1\n",
    "    for i in range(len(names)):\n",
    "        try:\n",
    "            no_stroke_layer[i]=layers[0][names[i]]\n",
    "        except:\n",
    "            no_stroke_layer[i]=0\n",
    "        try:\n",
    "            stroke_layer[i]=layers[1][names[i]]\n",
    "        except:\n",
    "            stroke_layer[i]=0\n",
    "        total=no_stroke_layer[i]+stroke_layer[i]\n",
    "        no_stroke_layer[i]=no_stroke_layer[i]/total\n",
    "        stroke_layer[i]=stroke_layer[i]/total\n",
    "    plt.bar(position,no_stroke_layer, edgecolor='white')\n",
    "    plt.bar(position, stroke_layer, bottom=no_stroke_layer, edgecolor='white')\n",
    "    plt.title(feature)\n",
    "    plt.xticks(position, names, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:51:08.928457Z",
     "start_time": "2019-11-05T19:51:08.889560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:51:10.672853Z",
     "start_time": "2019-11-05T19:51:09.034550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(5,2,1)\n",
    "stacked_plot('gender')\n",
    "plt.subplot(5,2,2)\n",
    "stacked_plot('hypertension')\n",
    "plt.subplot(5,2,3)\n",
    "stacked_plot('heart_disease')\n",
    "plt.subplot(5,2,4)\n",
    "stacked_plot('ever_married')\n",
    "plt.subplot(5,2,5)\n",
    "stacked_plot('work_type')\n",
    "plt.subplot(5,2,6)\n",
    "stacked_plot('Residence_type')\n",
    "plt.subplot(5,2,7)\n",
    "stacked_plot('smoking_status')\n",
    "plt.subplot(5,2,8)\n",
    "stacked_plot('bmi_interp')\n",
    "plt.subplot(5,2,9)\n",
    "stacked_plot('diabetic_interp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This plot grid allows us to quickly see how stroke rates differ depending on variable. Based on observation it appears `hypertension`, `heart_disease`, `marriage_status`, `work _type`, `bmi_interp`, and `diabetes_interp` all seem to have an effect on stroke and seem to be promising candidate variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now lets analyze our predictor variables. Logistic regression is a mathematical model that estimates the probability of a binary outcomes. It is named after the logistic curve which takes the S-shape depicted below.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png?1566122052688\" alt=\"Logistic Curve\" title=\"Logistic Curve\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is our outcome? What information will a logistic regression model tell use about our outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Our primary outcome is whether the individual had a stroke. The logistic regression model will allow us to see how individuals variables affect whether an individual has a stroke **while controlling for other variables in the model**. For instance, we can see whether being older affects having a stroke while controlling for diabetes, heart disease, etc...\n",
    "\n",
    "Very useful indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Follow-Up:** What is statistical significance? What is a generally accepted level of statistical significance in healthcare research?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Statistical Significance can be defined as the chance that the relationship you observed in your data occurred by chance. What does this mean? Lets say our logistic regression model finds that gender has a statistically significant effect on having a stroke. This means that it is more likely that there is indeed a relationship between gender and stroke than chance would suggest. \n",
    "\n",
    "The conventional level of significance that is accepted is < 0.05 (this number is referred to as a p-value). This means that there is less than 5% chance that the observed relationship in the data was due to chance alone. The image below display a sample R output.\n",
    "\n",
    "<img src=\"https://drchrispook.files.wordpress.com/2017/02/anova-output-from-r1.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets create our logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:40:02.785458Z",
     "start_time": "2019-11-05T19:40:02.738532Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data.head()\n",
    "stroke_data.loc[stroke_data['stroke']=='History of stroke','stroke'] = 1\n",
    "stroke_data.loc[stroke_data['stroke']=='No stroke','stroke']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:40:05.538358Z",
     "start_time": "2019-11-05T19:40:05.465558Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data_X=stroke_data.drop(columns=['id','stroke','bmi','avg_glucose_level'])\n",
    "stroke_data_Y=stroke_data.stroke\n",
    "stroke_data_X=pd.get_dummies(stroke_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:40:06.235290Z",
     "start_time": "2019-11-05T19:40:06.209284Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:40:09.403429Z",
     "start_time": "2019-11-05T19:40:09.394585Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stroke_data_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:41:12.804501Z",
     "start_time": "2019-11-05T19:41:11.823499Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a Logistic Regression model\n",
    "import statsmodels.api as sm\n",
    "model = sm.GLM(stroke_data_Y,stroke_data_X)\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:41:12.920720Z",
     "start_time": "2019-11-05T19:41:12.809626Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that several of our variables do not have a statistically significant effect. Several of these variables are clinically relevant. This includes while BMI and diabetes status. While there is no statistically significant effect, we know that obesity and diabetes are clinical risk factors for atherosclerotic diseases (one of the underlying etiologies of stroke). For this reason we will be keeping it in our model. \n",
    "\n",
    "While statistical significance is important, it is always more important to consider whether our predictor are clinically relevant for the outcome we will be predicting. In this case, many of the predictors in our model are clinically relevant for our outcome. For this reason we will be keeping them. Remember to alway consider the clinical significance of a variable and not just the statistical significance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building a Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** So far we haven't done any machine learning yet. What we've done can be considered traditional statistical analyses. What differentiates machine learning from traditional statistical analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "In machine learning, data is split into a training and test set. A machine learning model is then trainined on the training set to predict whatever outcome of interest it was designed to predict (in our case we're predicting whether the patient will have a stroke). The models predictive performance is then evaluated using the test set. \n",
    "\n",
    "<img src=\"https://www.sqlservercentral.com/wp-content/uploads/2019/05/Image-2.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Today we will be using a model called a random forest. A random forest is an algorithm built from numerous smaller algorithm called decision trees. Decision trees are charts which help make a decision or prediction. Each branch represents a possible outcome. The end of branches represent an end result or decision. \n",
    "\n",
    "Decision trees are common in medical settings. For instance, below is an algorithm for evaluating febrile seizures. This is an example of a decision tree.\n",
    "\n",
    "<img src=\"https://img.grepmed.com/uploads/1105/febrileseizure-management-algorithm-diagnosis-complex-original.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a random forest algorithm, the results of hundreds (and even thousands) of decision trees are calculated. These results are all combined. \n",
    "\n",
    "The rationale is that while a single decision tree can easily be wrong, the pooled result from numerous trees will be more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets split our data into a training and test set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:42:17.365691Z",
     "start_time": "2019-11-05T19:42:17.346608Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and test set data\n",
    "# Setting the seed value so we get the same result when we repreat\n",
    "X_train, X_test, y_train, y_test = train_test_split(stroke_data_X, stroke_data_Y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:42:19.010415Z",
     "start_time": "2019-11-05T19:42:18.991459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()\n",
    "y_test.value_counts()\n",
    "stroke_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now lets fit our random forest model to the training and test data. We will then take a look at our models performance using a confusion matrix.\n",
    "\n",
    "> If you're unsure what a confusion matrix is, please consult section 5.1.1 ('What is a Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:43:07.448515Z",
     "start_time": "2019-11-05T19:42:58.423620Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "clf=RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "print('Training Random Forest, please be patient...\\n')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "print('Testing Random Forest, please be patient...\\n')\n",
    "y_pred=clf.predict(X_test)\n",
    "                      \n",
    "# Output results\n",
    "print('Outputing results...')\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion matrix')\n",
    "print(conf_mat)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We see that our accuracy is over 90%. However, we did not correctly identify a single stroke. Would a model like this be useful? Absolutely not! All it could do is predict no strokes, the opposite of what we want!\n",
    "\n",
    "This is one of the weaknesses of random forests. Since the data is very imbalanced (ie. there are tons of negative results and only a few positive results), we can still maintain over 90% accuracy and not predict a single stroke. The algorithm is biased towards outcomes which maximizes its accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So what can we do? There are several approaches. We will be implementing a solution known as a weighted random forest. This will punish the algorithm more heavily for misclassifying the data. This is known as cost-sensitive learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:43:32.231931Z",
     "start_time": "2019-11-05T19:43:32.220495Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate the weight\n",
    "no_stroke=stroke_data_Y.value_counts()[0]\n",
    "have_stroke=stroke_data_Y.value_counts()[1]\n",
    "total=stroke_data_Y.shape[0]\n",
    "no_stroke_weight=total/(2*no_stroke)\n",
    "have_stroke_weight=total/(2*have_stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:44:16.983640Z",
     "start_time": "2019-11-05T19:44:08.243380Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "clf=RandomForestClassifier(n_estimators=500,class_weight={0:no_stroke_weight,1:have_stroke_weight})\n",
    "\n",
    "print('Training Random Forest, please be patient...\\n')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "print('Testing Random Forest, please be patient...\\n')\n",
    "y_pred=clf.predict(X_test)\n",
    "                      \n",
    "# Output results\n",
    "print('Outputing results...')\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion matrix')\n",
    "print(conf_mat)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Much better! This illustrates why accuracy can be a misleading metric for machine learning models. So if accuracy is not a great measure, what is? Continue on to find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What Is A Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A confusion matrix is a 2x2 table which computes 4 different combinations of predicted vs. actual values. The combinations are True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/320/1*Z54JgbS4DUwWSknhDCvNTQ.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    "These 4 interpretations can be combined to generate many useful metrics. For our purpose there are three we will focus on. The first is accuracy: \n",
    "\n",
    "\\[\\large (TP + TN)/Total\\]\n",
    "\n",
    "Accuracy allows us to measure how often our model predicted correctly. The second metric is sensitivity:\n",
    "\n",
    "\\[\\large TP / (TP + FN)\\]\n",
    "\n",
    "Sensitivity asks the question, that when our outcome is actually positive (ie. in our case when our patient is actually high-risk) how often will the model predict positively (ie. how often will the model then predict the patient to be high-risk). The final metric is specificity:\n",
    "\n",
    "\\[\\large FP / (FP + TN)\\]\n",
    "\n",
    "Specificity asks the question, that when the outcome is actually negative (ie. in our case when our patient is actually low-risk) how often will the model predict negatively (ie. how often will the model then predict the patient to be low-risk). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will be evaluating our model using a receiver operating curve (ROC) and the area under the curve (AUC) value. \n",
    "\n",
    "> If you're unsure what a ROC or AUC value is, please consult section 5.1.1 ('Understanding ROC Curves and AUC Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:44:38.885737Z",
     "start_time": "2019-11-05T19:44:38.516993Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot a ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Compute fpr, tpr, thresholds and roc auc\n",
    "roc_curve(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:44:40.138310Z",
     "start_time": "2019-11-05T19:44:40.131386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate the area under the curve (AUC)\n",
    "print('AUC:', roc_auc.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The closer to the top left corner our ROC curve is the better. The higher our AUC value is the better. These metrics provide useful measure when tuning our model. They are also better overall measures than accuracy alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Understanding ROC Curves and AUC Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An ROC plots sensitivity (probability of predicting a real psoitive will be positive) against 1-specificity (the probability of predicting a real negative will be a positive). A model with a 50-50 change of making a correct decision will have a ROC curve which is just a diagonal line. A model with a curve that hugs the top left corner is a perfect model. The area under a curve is a measure of magnitude of the ROC curve. The closer the ROC curve is to the top left corner, the higher the AUC value is. The higher the AUC value is, the better. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/406/1*pk05QGzoWhCgRiiFbz-oKQ.png\" style=\"float: center; width: 34%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Explaining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important part of any model is being able to explain it. We will be measuring variable importance using a measure called a **Gini Score**. The mathematics of the **Gini Score** are beyond the scope of the case. For our model, the higher the decrease in gini score, the more important that variable is for our model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:44:54.409478Z",
     "start_time": "2019-11-05T19:44:53.796335Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features=X_train.columns\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From our model we can see that age is by far the most important variable for performance. Surprisingly we can see work type and marriage status are important variables as well. In fact, they are even more important than some of our traditional clinical variables! This doesn't necessarily mean being married will definitely lead to a stroke. This just indicate that these variables are important for our models performance. Regardless, this reveals non-traditional variables worth future investigation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Congratulations! You've reached the end of the case! This case provided just one example of how analytics and healthcare can be combined to solve clinical problems. I hope your curiosity has been piqued. There much more to learn and much more you can explore in this field!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "414px",
    "left": "54px",
    "top": "110.8px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.4px",
    "left": "432px",
    "right": "20px",
    "top": "129px",
    "width": "542.925px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
