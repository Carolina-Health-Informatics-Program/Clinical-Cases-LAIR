{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p align=\"justify\">Welcome! In this case we'll be exploring how to use advanced analytic and machine learning techniques to predict strokes. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Some of the skills you'll explore are (Click to Expand):</summary>\n",
    "<ul>\n",
    "    <li>Python Programming</li>\n",
    "    <li>Data Cleaning</li>\n",
    "    <li>Exploratory Data Analysis</li>\n",
    "    <li>Data Visualization</li>\n",
    "    <li>Leveraging Domain Knowledge</li>\n",
    "    <li>Machine Learning</li>\n",
    "    <li>Random Forest Algorithm</li>\n",
    "</details><br>\n",
    "Don't worry if you're unsure what some of these terms are. They'll be explained throughout the case. Let's begin! \n",
    "\n",
    "<img src=\"https://www.fromthegenesis.com/wp-content/uploads/2018/06/RanFore.jpg\" style=\"float: left; width: 34%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSxzj-rl3NFqS8Iow-h_3cE2mJoINBs9ZFOjo-tx44d86KiRja7\" style=\"float: left; width: 33%; margin-left: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://www.edvancer.in/wp-content/uploads/2015/10/f5bd5f87059fce20564f6e5eb562022e.png\" style=\"float: left; width: 27%; margin-left: 1%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Why Use/Learn Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Python is a multi-paradigm programming language: a sort of Swiss Army knife for the coding world. It supports objected-oriented programming, structured programming, and functional programming patterns, among other. Thanks to Python's focus on simplicity and readability, it boasts a gradual and relatively low learning curve.\n",
    "\n",
    "Python is a powerful tool for both data analysis and data visualization. First, the tool is free to use and download! Its a open-source programming language meaning anyone in the world can contribute and enhance the capabilities of Python. Thanks to Python's large community, there are numerous extensions for Python called packages that expands its capabilities. This includes enhanced data visualization graphics and machine learning, both of which will be showcased in this cases. \n",
    "\n",
    "For those interested in learning more about Python see below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Case Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine you're an emergency physician at a local community hospital. Your hospital has recently joined a regional initiative to improve quality of care for stroke. After undergoing over a decade of training, you're well-versed in the clinical manifestations of stroke. Still, you know there is great uncertainty in diagnosing and treating stroke. The window for treatment is narrow and the drugs involved can have dangerous side-effects. Can analytics and machine learning help with this uncertainty?\n",
    "\n",
    "Continue the case to find out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clinical Background: Stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Stroke is an acute neurologic condition referred to as a cerebrovascular event. This means stroke is a condition that affects the brain (\"cerebro-\") and involves blood vessels (\"vascular). In stroke, arteries leading to and within the brain are either blocked by a clot or rupture. The end result is lack of oxygen and nutrients to the brain leading to brain damage. \n",
    "\n",
    "<center>\n",
    "  <img width=\"500\" height=300 src=\"https://www.strokeinfo.org/wp-content/uploads/2019/06/HTN_16_pg39_art600x400.png\">\n",
    "<\\center>\n",
    "\n",
    "Stroke is usually diagnosed clinically (by symptoms) and imaging (non-contrast head CT scan). Stroke can exhibit a wide range of symptoms depending on the location affected within the brain. Some nonspecific symptoms include headache (\"worst headache of my life\", nausea, vomiting, loss of consciousness, and neck stiffness. If suspected a non-contrast head CT is ordered to detect bleeding. Depending on whether the stroke is caused by a clot or rupture, treatment will be different. A clot will be treated with blood thinners. A rupture will be treated through emergent neurosurgery. \n",
    "\n",
    "> Stroke require prompt diagnosis and treatment before irreversible damages sets in. Any tool (such as a predictive model) that could make stroke diagnosis quicker or easier could make a large difference in preventing stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using Jupyter Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To run any of the code, select the code cell on the **bottom right (1.2)**, and click the `Run` button on the toolbar above. Try it out on the example code cell below on the **bottom right (1.2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "source": [
    "**The** `Run` **Button**\n",
    "<img src=\"https://i.imgur.com/jr4dpLW.png\" style=\"width:300px;height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:42.329916Z",
     "start_time": "2019-11-18T01:01:42.303708Z"
    },
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is an example of a code cell\n",
    "print('Congratulations!')\n",
    "print('You\\'ve run your first code cell.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Jupyter Notebook Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is a Jupyter Notebook? Why is it so special? Below is a definition of Jupyter Notebook from the creators. \n",
    "\n",
    "> \"The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\" - [jupyter.org](https://www.jupyter.org)\n",
    "\n",
    "Through integrating code, text, and multimedia, jupyter notebooks allow us to create a digital notebook that is both **interactive** and **informative**. Don't just take my word for it though, personally explore how Jupyter Notebook can augment your learning through the case!\n",
    "\n",
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/1-LPnY8nOLg4S6_TG0DEXwsg-1.png\" style=\"width:600px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Case Code Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Within code cells you will see green text preceded by a `#` symbol. These are comments and will help explain what portions of the code are doing. All code should be ready to run as shown. \n",
    "\n",
    "Some code may require more time to run. On the left hand side you will notice the label: `In [ ]:`. If there is an `*` in between the `[]`'s after you select `Run`, that indicates that your code is in the process of running. Like so: `In [*]:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Meeting Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll be using a deidentified set of patient data made available on [kaggle](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1), a data science community website. The data was originally provided by Mckinsey Analytics for a online hackathon hosted by Analytics Vidhya.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p style=\"text-align: center;\">stroke_predict.csv</p>\n",
    "\n",
    "***\n",
    "This file contains our dataset. There are a little over 43,000 patients with 12 variables. The data includes general demographic and clinical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset will already be downloaded for the case. The The original data can be acceded [here](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Consulting the Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are several variables or labels which you might not understand. There are many reasons for this. You might lack domain experience for the data you're analyzing. The data creators might also have used arbitrary labels only they understood (this is considered a bad practice).\n",
    "\n",
    "The way to combat this is by consulting the data dictionary or documentation. These are tables or documents which describe the data in detail. Have a variable you don't understand? Check the documentation! Don't understand what an output for a variable means? Check the documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A data dictionary is provided on the [kaggle page](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1#Screen%20Shot%202018-04-17%20at%2012.15.42%20AM.png) where the data is hosted. The data dictionary has also been reproduced below for your convenience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Variable*        | *Definition*                                           |\n",
    "| ----------------- | ------------------------------------------------------ |\n",
    "| id                | Patient ID                                             |\n",
    "| gender            | Gender of Patient                                      |\n",
    "| age               | Age of Patient                                         | \n",
    "| hypertension      | 0 - no hypertension, 1 - suffering from hypertension   |\n",
    "| heart_disease     | 0 - no heart disease, 1 - suffering from heart disease |\n",
    "| ever_married      | Yes/No                                                 |\n",
    "| work_type         | Type of occupation                                     |\n",
    "| Residence_type    | Area type of residence (Urban/ Rural                   |\n",
    "| avg_glucose_level | Average Glucose level (measured after meal)            |\n",
    "| bmi               | Body mass index                                        |\n",
    "| smoking_status    | patient's smoking status                               |\n",
    "| stroke            | patient's smoking status                               |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup (Do Not Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the code below to set up specific settings for our case. Do not skip this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.249541Z",
     "start_time": "2019-11-19T15:16:49.196539Z"
    },
    "hidden": true,
    "tags": [
     "#setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Calling external libraries for additional functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas.api.types import CategoricalDtype \n",
    "plt.style.use('fivethirtyeight')\n",
    "# Increase max number of columns displayed in output tables\n",
    "pd.set_option(\"display.max_columns\",2000)\n",
    "\n",
    "# Make sure your ML results are the same\n",
    "random.seed(10)\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cleaning Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first step in any analytic project is to clean our data. This is a critical step that is commonly overlooked within data science projects. This is critical for making our data convenient to interpret and manipulate. In addition, many analytic techniques require properly formatted data. Healthcare datasets may also have data that isn't clinically relevant (ie. raw lab values). Processing can convert these variables into clinically meaningful information. It won't matter how sophisticated our analysis is if we don't properly process our data. A common saying in data science is \"Junk in, Junk out\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Reading Our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll begin by reading in our data so we can clean and use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.363774Z",
     "start_time": "2019-11-19T15:16:51.252740Z"
    },
    "cell_style": "center",
    "hidden": true,
    "tags": [
     "#read_data",
     "=>setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Note: Unicode Transformation Format – 8 (UTF-8) is a standard to encode characters in different languages\n",
    "print('Data loading, please wait')\n",
    "stroke_data = pd.read_csv(\"data/stroke_predict.csv\",  encoding=\"UTF-8\" ,sep=\",\")\n",
    "print('Data loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's get an overview of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:47.485376Z",
     "start_time": "2019-11-18T01:01:47.457479Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#clean1",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:47.522801Z",
     "start_time": "2019-11-18T01:01:47.488369Z"
    },
    "hidden": true,
    "tags": [
     "#clean2",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Take a minute to look over the output. The first output is the first few rows of our data. The second output gives the structure of our data which includes variable name and the type of variable it is. We can see that many variables have not been coded into an easily human-readable format (ie. `hypertension`, `heart_disease`, `stroke`). We will also need to convert some of the clinical variables into meaningful categories (`avg_glucose_level` and `bmi`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Recoding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our first task will be recoding the variables `hypertension` (high blood pressure), `heart_disease`, and `stroke` into something meaningful. Based upon the data dictionary, we can see that a value of `1` for any of these fields indicates the patient is suffering from this condition. A value of `0` indicates they are not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.442122Z",
     "start_time": "2019-11-19T15:16:51.367101Z"
    },
    "hidden": true,
    "tags": [
     "#clean3",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "# Recoding\n",
    "stroke_data.loc[stroke_data['hypertension']==1,'hypertension'] = 'History of hypertension'\n",
    "stroke_data.loc[stroke_data['hypertension']==0,'hypertension'] = 'No hypertension'\n",
    "stroke_data.loc[stroke_data['heart_disease']==1,'heart_disease'] = 'History of heart disease'\n",
    "stroke_data.loc[stroke_data['heart_disease']==0,'heart_disease'] = 'No heart disease'\n",
    "stroke_data.loc[stroke_data['stroke']==1,'stroke'] = 'History of stroke'\n",
    "stroke_data.loc[stroke_data['stroke']==0,'stroke']='No stroke'\n",
    "\n",
    "print('Data Recoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:48.050171Z",
     "start_time": "2019-11-18T01:01:48.033229Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#clean4",
     "=>clean3"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data[['hypertension','heart_disease','stroke']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:48.074065Z",
     "start_time": "2019-11-18T01:01:48.053589Z"
    },
    "hidden": true,
    "tags": [
     "#clean5",
     "=>clean3"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data[['hypertension','heart_disease','stroke']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks like our changes were successful. In the output, notice the `object`. This is Python's way to tell us that Python considers these as categorical variables. This just means Python considers this a text or 'string' variable. The majority of variable you encounter in a an analysis will likely be numeric or categorical variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is the difference between a numeric and categorical variable? What kind of variable should we convert our three variables above into?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "shown"
   },
   "source": [
    "- **Numeric:** variables whose values are whole numbers (ie. numbers, percents)\n",
    "- **Categorical:** variables whose values are selected from a group (ie. dog breeds, male/female) \n",
    "\n",
    "We should convert these variables into categorical variables because these variables have only a limited number of categories. \n",
    "\n",
    "> Note R calls categorical variables **category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.465505Z",
     "start_time": "2019-11-19T15:16:51.445234Z"
    },
    "hidden": true,
    "tags": [
     "#clean6",
     "=>clean3"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.hypertension.astype('category')\n",
    "stroke_data.heart_disease.astype('category')\n",
    "stroke_data.stroke.astype('category')\n",
    "\n",
    "print('Conversion complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It important to make sure your variables are encoded correctly in an analysis. Incorrectly encoded variables can ultimately affect the results of any predictive models or analysis you produce leading to faulty conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Why is checking for missing data important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Missing data can produce biased results or lead to lead to reduced statistical power of our analysis (by reducing our sample size)\n",
    "\n",
    "Missing data are a common feature of messy, real-world data. How you choose to deal with missing data will have a big impact on your analysis and any predictive model you build. There are several ways to deal with missing data such as removing or imputing missing data. More details on handling missing data in Python can be found [here](https://machinelearningmastery.com/handle-missing-data-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let examine our data for missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:49.870085Z",
     "start_time": "2019-11-18T01:01:49.825073Z"
    },
    "hidden": true,
    "tags": [
     "#clean7",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "print('Number of Missing Data for Each Variable:')\n",
    "stroke_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Besides `bmi` our data looks exceptionally clean. This rarely happens. It is more likely that our data is not coded correctly. Lets examine our data more closely. Keep in mind Python classifies missing `NaN`. Look for odd symbols that Python may not be registering as missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:50.096866Z",
     "start_time": "2019-11-18T01:01:50.068732Z"
    },
    "hidden": true,
    "tags": [
     "#clean8",
     "=>clean6"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that `smoking_status` has numerous `NaN` values. Lets take a closer look at `smoking_status`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:50.271897Z",
     "start_time": "2019-11-18T01:01:50.257162Z"
    },
    "hidden": true,
    "tags": [
     "#clean9",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.smoking_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:50.285086Z",
     "start_time": "2019-11-18T01:01:50.275076Z"
    },
    "hidden": true,
    "tags": [
     "#clean10",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "print('The number of missing values:' ,stroke_data.smoking_status.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T22:38:04.496464Z",
     "start_time": "2019-11-17T22:38:04.398882Z"
    },
    "hidden": true
   },
   "source": [
    "We can see that approximately 1/4 of `smoking status` values are blank! Lets make sure R can recognize these values as missing now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.493255Z",
     "start_time": "2019-11-19T15:16:51.469700Z"
    },
    "hidden": true,
    "tags": [
     "#clean11",
     "=>clean6"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.smoking_status.fillna('never smoked',inplace=True)\n",
    "stroke_data.smoking_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Much better! Keep in mind different dataset encode missing or abnormal values differently. Even different programming languages encode missing values in their unique way. You need to watch out for these differences whenever dealing with a new dataset or tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Checking for Implausible Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets check our data for implausible values. Focus on the minimum and maximum values for the numeric output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:51.008194Z",
     "start_time": "2019-11-18T01:01:50.955471Z"
    },
    "hidden": true,
    "tags": [
     "#clean12",
     "=>clean11"
    ]
   },
   "outputs": [],
   "source": [
    "# numerical variables\n",
    "stroke_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Among our variables, we can see that `bmi` has a maximum 97.60. It biologically unlikely for an individual to have a `bmi` of 97.60. Lets take a closer look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:51.178237Z",
     "start_time": "2019-11-18T01:01:51.162493Z"
    },
    "hidden": true,
    "tags": [
     "#clean13",
     "=>clean11"
    ]
   },
   "outputs": [],
   "source": [
    "print('BMI:')\n",
    "stroke_data.bmi.quantile((0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that the max `bmi` is a huge jump even compared to our 99th percentile. However, a `bmi` of 10.1, while underweight, is physiologically possible. Based on our finding, let's reclassify implausible values as `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.519127Z",
     "start_time": "2019-11-19T15:16:51.498676Z"
    },
    "hidden": true,
    "tags": [
     "#clean14",
     "=>clean11"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.loc[stroke_data.bmi > 60, 'bmi'] = np.nan\n",
    "print('Values Reclassified!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Creating Clinically Relevant Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our data includes two clinical measures: `avg_glucose_lvl` and `bmi`. As raw alb values, these variables do not provide useful information. Adding context can help with this. Creating clinically relevant variables will help us better communicate and understand how these variables affect our outcome (stroke status). We will be taking these measures and creating clinically meaningful variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI stands for Body Mass Index. This a measure of body weight based upon a person's weight and height. This measure is commonly used to evaluate whether a person is overweight. Below is the BMI formula. \n",
    "\n",
    "\\[\\large \\frac{weight (kg)}{[height (m)]^{2}}\\]\n",
    "\n",
    "We will create a new variable which reflects the clinical cutoffs for bmi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the clinical cut-offs for BMI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *BMI Range*     |\n",
    "| -------------- | --------------- |\n",
    "| Underweight    | BMI < 18.5      |\n",
    "| Healthy Weight | 18.5 ≤ BMI < 25 |\n",
    "| Overweight     | 25 ≤ BMI < 30   |\n",
    "| Obese          | 30 ≥ BMI        |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let create the new variable `bmi_interp` based off these cut-offs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.571114Z",
     "start_time": "2019-11-19T15:16:51.523263Z"
    },
    "hidden": true,
    "tags": [
     "#clean15",
     "=>clean14"
    ]
   },
   "outputs": [],
   "source": [
    "# Create 'bmi_interp'\n",
    "stroke_data.dropna(subset=['bmi'],inplace=True)\n",
    "stroke_data['bmi_interp'] = stroke_data.bmi.apply(lambda x: 'Underweight' if x < 18.5 \n",
    "                                                  else ('Health Weight' if x>=18.5 and x<25 \n",
    "                                                        else ('Overweight' if x>=25 and x<30 \n",
    "                                                              else 'Obese' )) )\n",
    "\n",
    "\n",
    "# Convert from character to categorical\n",
    "# Make sure is ordered\n",
    "stroke_data.bmi_interp=stroke_data.bmi_interp.astype(CategoricalDtype(categories=['Underweight', 'Health Weight',\n",
    "                                                                    'Overweight', 'Obese'], ordered=True))\n",
    "\n",
    "print('\\'bmi_interp\\' variable created!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:52.701972Z",
     "start_time": "2019-11-18T01:01:52.687899Z"
    },
    "hidden": true,
    "tags": [
     "#clean16",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data[['bmi','bmi_interp']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Limitations and Considerations when using BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI is a simple, inexpensive, and common measure for body fat. However, there are several clinical considerations to keep in mind when using this measure. It's critical to keep in mind BMI is only a surrogate measure since it uses weight instead of actual body fat content in its calculations. Below are three examples of factors that can influence BMI:\n",
    "\n",
    "- Age: older adults usually have more body fat than younger adults for the same BMI\n",
    "- Gender: women tend to have greater amounts of body fat compared to men for the same BMI\n",
    "- Muscle mass: muscular individuals or athletes may have higher BMI due to increased muscle mass\n",
    "\n",
    "[Source](https://www.cdc.gov/obesity/downloads/bmiforpactitioners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Average Glucose Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The data dictionary defines `avg_glucose_lvl` as the average glucose level measured after meals (glucose is another term for blood sugar levels). Glucose levels are commonly used to assess whether a patient has diabetes. A patient with diabetes will have on-average a higher blood glucose level.\n",
    "\n",
    "However, `avg_glucose_lvl`, as defined by the data dictionary, is clinically problematic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Food for Thought:** What's wrong with 'avg_glucose_lvl' as a measure of blood glucose levels? What is a better measure of average blood sugar status?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Individual's blood glucose can vary widely day to day. This is especially true after meals when individuals are experiencing a physiological spike in their glucose levels. \n",
    "\n",
    "[Here's a news article discussing inter-population variability in glucose measurements](https://www.medicalnewstoday.com/articles/322614.php)\n",
    "\n",
    "A better measure would be hemoglobin A1C which measures the amount of sugar attached to each red blood cell. This is an indication of the average blood glucose status of a patient over 2 to 3 months. \n",
    "\n",
    "<img src=\"https://www.ekfdiagnostics.com/res/HbA1c-Hemoglobin-banner\" style=\"text-align: center; width: 66%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can't change the measurements used in the data. However, just because the glucose measurement is not ideal doesn't mean we need to disregard it completely. Every bit of data counts in analytics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A good proxy for `avg_glucose_level` would be the cutoffs determined by the oral glucose tolerance test (OGTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the criteria for normal, prediabetic, and diabetic in the OGTT two hours after drinking??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *Blood Glucose (mg/dl)*   |\n",
    "| -------------- | ------------------------- |\n",
    "| Diabetic       | 200 ≤ Blood Glucose       |\n",
    "| Prediabetic    | 140 ≤ Blood Glucose < 200 |\n",
    "| Healthy        |  Blood Glucose < 140      |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now use these criteria to classify a patient's 'avg_glucose_level' as either normal, prediabetic, or diabetic based upon OGTT criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.596733Z",
     "start_time": "2019-11-19T15:16:51.575155Z"
    },
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true,
    "tags": [
     "#clean17",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "# Create 'diabetic_interp'\n",
    "stroke_data['diabetic_interp'] = stroke_data.avg_glucose_level.apply(lambda x: 'Healthy' if x < 140 \n",
    "                                                  else ('Prediabetic' if x>=140 and x<200\n",
    "                                                              else 'Diabetic')) \n",
    "\n",
    "\n",
    "# Convert from character to categorical\n",
    "stroke_data.diabetic_interp=stroke_data.diabetic_interp.astype(CategoricalDtype(categories=['Healthy', 'Prediabetic',\n",
    "                                                                    'Diabetic'], ordered=True))\n",
    "\n",
    "print('\\'diabetic_interp\\' variable created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.618542Z",
     "start_time": "2019-11-19T15:16:51.599767Z"
    },
    "hidden": true,
    "tags": [
     "#clean18",
     "=>clean17"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data[['avg_glucose_level','diabetic_interp']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This section was an important demonstration about how to utilize domain knowledge when processing your data (referred to as feature engineering by the machine learning community). Almost all analytic project will require you to communicate results to non-technical stakeholders. Creating domain specific variables, such as we did, is a critical part to helping other understand your results and analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've cleaned our data we can begin exploring our data. Using this, we can see which variables (features) are good candidates for building our prediction model. Feature selection  will determine how good or how bad your model is. Bad feature selection can have a negative impact on your model even if you used the most advanced techniques. Understanding the clinical nuances of your data can inform better feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Why Can't We Just Use All or Most Variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One issue you might be wondering about is why do we even need to select variables. Why not just use all of the variables? After all, more data lead to better models right? This is a common misconception that even experienced analysts need to watch out for. Including too many features in your prediction model can lead to what is known as **overfitting**.\n",
    "\n",
    "<img src=\"https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1527613915658.png\" align=\"center\" style=\"width: 50%; margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    " **Overfitting** is essentially where you build a model that adheres too closely to your current data set and is unable to predict observations that are not from your current data set. In other words, its where you develop a model that tuned too closely to your current data, and is not generalizable to outside data sources. A prediction model that is not generalizeable is not a useful model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Getting A Closer Look At Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets take a closer look as we begin our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:55.943002Z",
     "start_time": "2019-11-18T01:01:55.918376Z"
    },
    "hidden": true,
    "tags": [
     "#EDA1",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:55.989023Z",
     "start_time": "2019-11-18T01:01:55.945839Z"
    },
    "hidden": true,
    "tags": [
     "#EDA2",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:56.021180Z",
     "start_time": "2019-11-18T01:01:55.992063Z"
    },
    "cell_style": "split",
    "hidden": true,
    "tags": [
     "#EDA3",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.gender.value_counts()\n",
    "stroke_data.hypertension.value_counts()\n",
    "stroke_data.heart_disease.value_counts()\n",
    "stroke_data.ever_married.value_counts()\n",
    "stroke_data.work_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:56.050459Z",
     "start_time": "2019-11-18T01:01:56.023619Z"
    },
    "cell_style": "split",
    "hidden": true,
    "tags": [
     "#EDA4",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.Residence_type.value_counts()\n",
    "stroke_data.smoking_status.value_counts()\n",
    "stroke_data.stroke.value_counts()\n",
    "stroke_data.bmi_interp.value_counts()\n",
    "stroke_data.diabetic_interp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This output presents us with quite a bit of data. The first thing to realize is that the output will differ based on whether the variable is numeric or categorical. Numeric outputs will include summary statistics while categorical variables will include frequency counts of each category. \n",
    "\n",
    "These summaries will provide a useful reference throughout our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "Missing data can bias the results of our analysis. For instance, say that the individuals that did not respond about smoking status refused to respond because they were embarrassed of their smoking habit. This might make smoking individuals more likely to be smokers compared to individuals that responded to the survey. \n",
    "\n",
    "In summary, missing data can be problematic, especially if the missing group is somehow different from the non-missing group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T23:11:06.841206Z",
     "start_time": "2019-11-17T23:11:06.834084Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Assessing Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets take a look at our other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:57.383885Z",
     "start_time": "2019-11-18T01:01:57.350282Z"
    },
    "hidden": true,
    "tags": [
     "#EDA5",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:57.430130Z",
     "start_time": "2019-11-18T01:01:57.387184Z"
    },
    "hidden": true,
    "tags": [
     "#EDA6",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "Based on our output above what are the numeric feature(s) we would consider for our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have some summary statistics about age available. Lets take a look at the distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "We can see that there are a couple numeric variables. However, the only one we would consider is `age`. While `bmi` and `avg_glucose_level` are both numeric variables, they both have newer and more clinically relevant variables available. Including both the raw lab values and the newer interpretation variables for these two would be redundant and could lead to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:58.399427Z",
     "start_time": "2019-11-18T01:01:57.924616Z"
    },
    "hidden": true,
    "tags": [
     "#EDA7",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Plot\n",
    "plt.figure(figsize=(15,15))\n",
    "n, bins, patches=plt.hist(stroke_data.age,bins='auto', alpha=0.7, rwidth=0.85)\n",
    "xlabel=plt.xlabel('Age (years)')\n",
    "ylabel=plt.ylabel('Frequency Count')\n",
    "plt.axvline(stroke_data.age.median(), color='r',linestyle='dashed')\n",
    "plt.text(45,1500,'Dashed Line Represents Median Age (44 Years)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There does not appear to be any extreme age values or prominent age clusters. Now lets see if theres a relationship between stroke status and age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Do you expect there to be a relationship between stroke status and age? Why? Keep in mind your answer before seeing the output below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:58.867412Z",
     "start_time": "2019-11-18T01:01:58.402058Z"
    },
    "hidden": true,
    "tags": [
     "#EDA8",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.violinplot(y=stroke_data.stroke,x=stroke_data.age,orient='h')\n",
    "print('The dots in the center of each violin plot represent median age of each group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Based on our results, does age have an effect on stroke status? What could explain our results? Do our results indicate age would be a good candidate variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "The results are pretty stark. Both median age and distribution of age drastically differs between the stroke and non-stroke group. As age increases, we can see the the distribution of strokes increases. This can likely be explained by the fact that individuals over the age of 55 are the most likely to have a stroke with stroke risk increasing as an individual ages further. This is because individual arteries become narrower and and stiffer with age increasing the risk of a cerebrovascular event. \n",
    "\n",
    "These results indicate age is an excellent candidate variable for our model since age seems to have a large effect on stroke status. This indicates our model could use age to differentiate between stroke and no stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally lets look at our remaining variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:59.178712Z",
     "start_time": "2019-11-18T01:01:59.155129Z"
    },
    "hidden": true,
    "tags": [
     "#EDA9",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:01:59.214327Z",
     "start_time": "2019-11-18T01:01:59.182568Z"
    },
    "hidden": true,
    "tags": [
     "#EDA10",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Based on our output, which variables are categorical and would we be exploring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Our variables of interest will be `gender`, `hypertension`, `heart_disease`, `ever_married`, `work_type`, `Residence_type`, `smoking_status`, `stroke`, `bmi_interp`, and `diabetic_interp`\n",
    "\n",
    "Remember Python considers categorical variables as `object` or `category` variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let examine the effect our categorical variables have on stroke through using a stacked bar plot. Before continuing consider which variables you believe will have the largest effect and which will not. For instance, do you expect `hypertension` to have an effect. Do you expect it to have more of an effect than whether the individual had heart disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:02:01.841033Z",
     "start_time": "2019-11-18T01:01:59.764221Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "tags": [
     "#EDA11",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "def stacked_plot(feature):\n",
    "    binary=stroke_data.groupby('stroke')\n",
    "    length=len(stroke_data[feature].unique())\n",
    "    layers=[]\n",
    "    for symbol, group in binary:\n",
    "        sequence=group[feature].value_counts().index\n",
    "        temp=[]\n",
    "        try:\n",
    "            for i in range(length):\n",
    "                number=group[feature].value_counts()[i]\n",
    "                temp.append(number)\n",
    "        except:\n",
    "            print('there\\'s no case for at least one category ')\n",
    "        temp=dict(zip(sequence,temp))\n",
    "        layers.append(temp)\n",
    "    names=stroke_data[feature].unique()\n",
    "    no_stroke_layer=[0]*len(names)\n",
    "    stroke_layer=[0]*len(names)\n",
    "    position=np.arange(len(names))+1\n",
    "    for i in range(len(names)):\n",
    "        try:\n",
    "            no_stroke_layer[i]=layers[0][names[i]]\n",
    "        except:\n",
    "            no_stroke_layer[i]=0\n",
    "        try:\n",
    "            stroke_layer[i]=layers[1][names[i]]\n",
    "        except:\n",
    "            stroke_layer[i]=0\n",
    "        total=no_stroke_layer[i]+stroke_layer[i]\n",
    "        no_stroke_layer[i]=no_stroke_layer[i]/total\n",
    "        stroke_layer[i]=stroke_layer[i]/total\n",
    "    plt.bar(position,no_stroke_layer, edgecolor='white')\n",
    "    plt.bar(position, stroke_layer, bottom=no_stroke_layer, edgecolor='white')\n",
    "    plt.title(feature)\n",
    "    plt.xticks(position, names, fontweight='bold')\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(5,2,1)\n",
    "stacked_plot('gender')\n",
    "plt.subplot(5,2,2)\n",
    "stacked_plot('hypertension')\n",
    "plt.subplot(5,2,3)\n",
    "stacked_plot('heart_disease')\n",
    "plt.subplot(5,2,4)\n",
    "stacked_plot('ever_married')\n",
    "plt.subplot(5,2,5)\n",
    "stacked_plot('work_type')\n",
    "plt.subplot(5,2,6)\n",
    "stacked_plot('Residence_type')\n",
    "plt.subplot(5,2,7)\n",
    "stacked_plot('smoking_status')\n",
    "plt.subplot(5,2,8)\n",
    "stacked_plot('bmi_interp')\n",
    "plt.subplot(5,2,9)\n",
    "stacked_plot('diabetic_interp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Based on our results, what variables seem to have an effect on stroke status? Does this make them good candidate variables for our prediction model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "This plot grid allows us to quickly see how stroke rates differ depending on variable. Based on observation it appears `hypertension`, `heart_disease`, `marriage_status`, `work _type`, `bmi_interp`, and `diabetes_interp` all seem to have an effect on stroke and seem to be promising candidate variables. \n",
    "\n",
    "Not surprisingly, having an associated comorbidity ( `hypertension`, `heart_disease`) has some of the largest effects on having a stroke. Both of these conditions are associated with cardiovascular disease cardiovascular disease (hypertension can damage arteries; heart disease will worsen arterial narrowing). Surprisingly, marriage status has a large effect on stroke as well. Perhaps individuals that are married are on average older or lead more sedentary lifestyles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now lets analyze our predictor variables. Logistic regression is a mathematical model that estimates the probability of a binary outcomes. It is named after the logistic curve which takes the S-shape depicted below.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png?1566122052688\" alt=\"Logistic Curve\" title=\"Logistic Curve\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is our outcome? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Our primary outcome is whether the individual had a stroke. \n",
    "\n",
    "The logistic regression model will allow us to see how individuals variables affect whether an individual has a stroke **while controlling for other variables in the model**. For instance, we can see whether being older affects having a stroke while controlling for diabetes, heart disease, etc..\n",
    "\n",
    "Very useful indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "We will be using logistic regression to assess whether our variables have a statistically significant effect on whether a person has a stroke. \n",
    "\n",
    "Statistical significance is how likely a relationship between variables in our data did not occur by chance. For example, if we find that age has a statistically significant effect on having a stroke, this means that this effect is more likely than chance alone would suggest. \n",
    "\n",
    "The conventional level of significance that is accepted is < 0.05 (this number is referred to as a p-value). This means that there is less than 5% chance that the observed relationship was due to chance alone. The image below display a sample R output with the p-value highlighted.\n",
    "\n",
    "<img src=\"https://drchrispook.files.wordpress.com/2017/02/anova-output-from-r1.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em; width: 75%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets create a logistic model using our chosen candidate predictor variables. Look at the p-value column to see whether our variables are statistically significant. Remember, we want our variables to have a p-value < 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.680330Z",
     "start_time": "2019-11-19T15:16:51.621629Z"
    },
    "hidden": true,
    "tags": [
     "#EDA12",
     "=>clean18"
    ]
   },
   "outputs": [],
   "source": [
    "# Establishing our outcomes\n",
    "stroke_data.head()\n",
    "stroke_data.loc[stroke_data['stroke']=='History of stroke','stroke'] = 1\n",
    "stroke_data.loc[stroke_data['stroke']=='No stroke','stroke']=0\n",
    "# Setting up for logistic regression model\n",
    "stroke_data_X=stroke_data.drop(columns=['id','stroke','bmi','avg_glucose_level', 'work_type', \n",
    "                                        'ever_married', 'Residence_type', 'gender', 'smoking_status'])\n",
    "stroke_data_Y=stroke_data.stroke\n",
    "stroke_data_X=pd.get_dummies(stroke_data_X)\n",
    "\n",
    "print('Ready to create logistic regression model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:02:03.329251Z",
     "start_time": "2019-11-18T01:02:02.046795Z"
    },
    "hidden": true,
    "tags": [
     "#EDA13",
     "=>EDA12"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a Logistic Regression model\n",
    "import statsmodels.api as sm\n",
    "model = sm.GLM(stroke_data_Y,stroke_data_X)\n",
    "result = model.fit()\n",
    "# Output Results\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that several of our variables do not have a statistically significant effect (`work_type`, `ever_married`, and `bmi_interp`). This indicates that these variables may not be good candidate predictor variables. For this reason, we will not be using `work_type` and `ever_married`. However, we will be using `bmi_interp` because we know that clinically, metabolic factors have a significant effect on stroke risk. This is because many of causes of being overweight (ie. sedentary lifestyle and unhealthy diet) can lead to build up of plaques in arteries. This increases the risk for stroke. \n",
    "\n",
    "While statistical significance is important, it is always more important to consider whether our predictor are clinically relevant for the outcome we will be predicting. Remember to alway consider the clinical significance of a variable and not just the statistical significance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building a Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** So far we haven't done any machine learning yet. What we've done can be considered traditional statistical analyses. What differentiates machine learning from traditional statistical analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "In machine learning, data is split into a training and test set. A machine learning model is then trainined on the training set to predict whatever outcome of interest it was designed to predict (in our case we're predicting whether the patient will have a stroke). The models predictive performance is then evaluated using the test set. \n",
    "\n",
    "<img src=\"https://www.sqlservercentral.com/wp-content/uploads/2019/05/Image-2.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For our case, we will be using a model called a random forest. A random forest is an algorithm built from numerous smaller algorithm called decision trees. Decision trees are charts which help make a decision or prediction. Each branch represents a possible outcome. The end of branches represent an end result or decision. \n",
    "\n",
    "Decision trees are common in medical settings. For instance, below is an algorithm for evaluating febrile seizures. This is an example of a decision tree.\n",
    "\n",
    "<img src=\"https://img.grepmed.com/uploads/1105/febrileseizure-management-algorithm-diagnosis-complex-original.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a random forest algorithm, the results of hundreds (and even thousands) of decision trees are calculated. These results are all combined. \n",
    "\n",
    "The rationale is that while a single decision tree can easily be wrong, the pooled result from numerous trees will be more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets split our data into a training and test set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:51.713450Z",
     "start_time": "2019-11-19T15:16:51.684420Z"
    },
    "hidden": true,
    "tags": [
     "#ML1",
     "=>EDA12"
    ]
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and test set data\n",
    "# Setting the seed value so we get the same result when we repreat\n",
    "X_train, X_test, y_train, y_test = train_test_split(stroke_data_X, stroke_data_Y, test_size=0.2, random_state=100)\n",
    "\n",
    "y_train.value_counts()\n",
    "y_test.value_counts()\n",
    "stroke_data.shape\n",
    "\n",
    "print('Training and Test Data Created')\n",
    "# Set up the model\n",
    "clf=RandomForestClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now lets fit our random forest model to the training and test data. We will then take a look at our models performance using a confusion matrix.\n",
    "\n",
    "> If you're unsure what a confusion matrix is, please consult section 5.0.1 ('What is a Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:02:11.448699Z",
     "start_time": "2019-11-18T01:02:04.200598Z"
    },
    "hidden": true,
    "tags": [
     "#ML2",
     "=>ML1"
    ]
   },
   "outputs": [],
   "source": [
    "print('Training Random Forest, please be patient...\\n')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "print('Testing Random Forest, please be patient...\\n')\n",
    "y_pred=clf.predict(X_test)\n",
    "                      \n",
    "# Output results\n",
    "print('Outputing results...')\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion matrix')\n",
    "print(conf_mat)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Do you notice anything strange about our model's performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "We see that our accuracy is over 90%. However, we did not correctly identify a single stroke. All this model could do is predict no strokes, the opposite of what we want!\n",
    "\n",
    "This is one of the weaknesses of random forests. Since the data is very imbalanced (ie. there are tons of negative results and only a few positive results), we can still maintain over 90% accuracy and not predict a single stroke. The algorithm is biased towards outcomes which maximizes its accuracy. \n",
    "\n",
    "We will be implementing a solution known as a weighted random forest. This will punish the algorithm more heavily for misclassifying the data. This is known as cost-sensitive learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:57.174168Z",
     "start_time": "2019-11-19T15:16:51.716513Z"
    },
    "hidden": true,
    "tags": [
     "#ML3",
     "=>ML1"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the weight\n",
    "no_stroke=stroke_data_Y.value_counts()[0]\n",
    "have_stroke=stroke_data_Y.value_counts()[1]\n",
    "total=stroke_data_Y.shape[0]\n",
    "no_stroke_weight=total/(2*no_stroke)\n",
    "have_stroke_weight=total/(2*have_stroke)\n",
    "\n",
    "# Set up the model\n",
    "clf=RandomForestClassifier(n_estimators=500,class_weight={0:no_stroke_weight,1:have_stroke_weight})\n",
    "\n",
    "print('Training Random Forest, please be patient...\\n')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "print('Testing Random Forest, please be patient...\\n')\n",
    "y_pred=clf.predict(X_test)\n",
    "                      \n",
    "# Output results\n",
    "print('Outputing results...')\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('confusion matrix')\n",
    "print(conf_mat)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Much better! This illustrates why accuracy can be a misleading metric for machine learning models. So if accuracy is not a great measure, what is? Continue on to find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What Is A Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A confusion matrix is a 2x2 table which computes 4 different combinations of predicted vs. actual values. The combinations are True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/320/1*Z54JgbS4DUwWSknhDCvNTQ.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    "These 4 interpretations can be combined to generate many useful metrics. For our purpose there are three we will focus on. The first is accuracy: \n",
    "\n",
    "\\[\\large (TP + TN)/Total\\]\n",
    "\n",
    "Accuracy allows us to measure how often our model predicted correctly. The second metric is sensitivity:\n",
    "\n",
    "\\[\\large TP / (TP + FN)\\]\n",
    "\n",
    "Sensitivity asks the question, that when our outcome is actually positive (ie. in our case when our patient is actually high-risk) how often will the model predict positively (ie. how often will the model then predict the patient to be high-risk). The final metric is specificity:\n",
    "\n",
    "\\[\\large FP / (FP + TN)\\]\n",
    "\n",
    "Specificity asks the question, that when the outcome is actually negative (ie. in our case when our patient is actually low-risk) how often will the model predict negatively (ie. how often will the model then predict the patient to be low-risk). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will be evaluating our model using a receiver operating curve (ROC) and the area under the curve (AUC) value. \n",
    "\n",
    "> If you're unsure what a ROC or AUC value is, please consult section 5.1.1 ('Understanding ROC Curves and AUC Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:02:18.867384Z",
     "start_time": "2019-11-18T01:02:18.585574Z"
    },
    "hidden": true,
    "tags": [
     "#ML4",
     "=>ML3"
    ]
   },
   "outputs": [],
   "source": [
    "# plot a ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Compute fpr, tpr, thresholds and roc auc\n",
    "roc_curve(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T01:02:18.875888Z",
     "start_time": "2019-11-18T01:02:18.870133Z"
    },
    "hidden": true,
    "tags": [
     "#ML5",
     "=>ML4"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the area under the curve (AUC)\n",
    "print('AUC:', roc_auc.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The closer to the top left corner our ROC curve is the better. The higher our AUC value is the better. The AUC value simply measures the area under our ROC curve. \n",
    "\n",
    "These metrics provide useful measures when tuning our model. They are also better overall measures than accuracy alone. We can compare different models using these two metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Understanding ROC Curves and AUC Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An ROC curve informs us about how good a model can classify between two outcomes (ie. if a patient has a disease or no disease).An ROC plots sensitivity (probability of predicting a true positive will be positive) against 1-specificity (the probability of predicting a real negative will be a positive). \n",
    "\n",
    "An ROC curve which hugs the top left corner indicate a model that can perfectly distinguishes between two outcomes. A model with a 50-50 chance of making a correct decision will have a ROC curve which is just a diagonal line. \n",
    "\n",
    "The area under a curve is a measure of magnitude of the ROC curve. The closer the ROC curve is to the top left corner, the higher the AUC value is. The higher the AUC value is, the better our prediction model is. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/406/1*pk05QGzoWhCgRiiFbz-oKQ.png\" style=\"float: center; width: 34%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Explaining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important part of any model is being able to explain it. One way we can exaplain our model is variable importance. This measures how much our given model uses a specific variable to make accurate predictions. Based on our results, which variables do you think will be the most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T15:16:57.569195Z",
     "start_time": "2019-11-19T15:16:57.176800Z"
    },
    "hidden": true,
    "tags": [
     "#ML6",
     "=>ML3"
    ]
   },
   "outputs": [],
   "source": [
    "features=X_train.columns\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From our model we can see that age is by far the most important variable for performance. This makes sense since the risk for stroke is dramatically higher in the elderly due to arterial narrowing and stiffening. We can see that our other variables are roughly similar in importance for our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Congratulations! You've reached the end of the case! This case provided just one example of how analytics and healthcare can be combined to solve clinical problems. I hope your curiosity has been piqued. There much more to learn and much more you can explore in this field!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "414px",
    "left": "54px",
    "top": "110.8px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.4px",
    "left": "432px",
    "right": "20px",
    "top": "129px",
    "width": "542.925px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
