{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p align=\"justify\">Welcome! In this case we'll be exploring how to use advanced analytic and machine learning techniques to predict strokes. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Some of the skills you'll explore are (Click to Expand):</summary>\n",
    "<ul>\n",
    "    <li>R Programming</li>\n",
    "    <li>Data Cleaning</li>\n",
    "    <li>Exploratory Data Analysis</li>\n",
    "    <li>Data Visualization</li>\n",
    "    <li>Leveraging Domain Knowledge</li>\n",
    "    <li>Machine Learning</li>\n",
    "    <li>Random Forest Algorithm</li>\n",
    "</details><br>\n",
    "Don't worry if you're unsure what some of these terms are. They'll be explained throughout the case. Let's begin! \n",
    "\n",
    "<img src=\"https://www.fromthegenesis.com/wp-content/uploads/2018/06/RanFore.jpg\" style=\"float: left; width: 34%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSxzj-rl3NFqS8Iow-h_3cE2mJoINBs9ZFOjo-tx44d86KiRja7\" style=\"float: left; width: 33%; margin-left: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://www.edvancer.in/wp-content/uploads/2015/10/f5bd5f87059fce20564f6e5eb562022e.png\" style=\"float: left; width: 27%; margin-left: 1%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Why Use/Learn R?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "R is a programming language that was designed by and for statisticians. This means that R can be difficult to read and learn. However, the time spent to learn R is well worth it.  \n",
    "\n",
    "R is a powerful tool for both data analysis and data visualization. First, the tool is free! Its a open-source programming language meaning anyone in the world can contribute and enhance the capabilities of R. Thanks to R's large community, there are numerous extensions for R called packages that expands its capabilities. This includes enhanced data visualization graphics and machine learning, both of which will be showcased in this cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Additional R resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To begin with R, you will need to download R itself [here](https://cran.r-project.org/). We then recommend you download R studio [here](https://cran.r-project.org/). R studio is a user interface for programming in R which provides several useful quality of life features that will make using and learning R easier. Finally, you can learn R interactively by using a service called 'swirl' which can be downloaded [here](https://swirlstats.com/students.html).\n",
    "\n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://2.bp.blogspot.com/-84sLSgXKYac/WwKFeEHk2II/AAAAAAAAIV8/p_tmTmPPpJc-WZefYZPYawT4OJ7SCrfCgCLcBGAs/s1600/rstudio1.PNG\" style=\"float: center; width: 66%; margin-bottom: 0.5em;\">\n",
    "  <center>\n",
    "  <figcaption>Rstudio Interface</figcaption>\n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "For those that want a deeper dive of R, two fantastic online books are below. Both of these books are free.\n",
    "\n",
    "- [Hands-on Programming with R](https://rstudio-education.github.io/hopr/) by Garrett Grolemund\n",
    "- [R for Data Science](https://r4ds.had.co.nz/) by Garrett Grolemund and Hadley Wickham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Case Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine you're an emergency physician at a local community hospital. Your hospital has recently joined a regional initiative to improve quality of care for stroke. After undergoing over a decade of training, you're well-versed in the clinical manifestations of stroke. Still, you know there is great uncertainty in diagnosing and treating stroke. The window for treatment is narrow and the drugs involved can have dangerous side-effects. Can analytics and machine learning help with this uncertainty?\n",
    "\n",
    "Continue the case to find out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clinical Background: Stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Stroke is an acute neurologic condition referred to as a cerebrovascular event. This means stroke is a condition that affects the brain (\"cerebro-\") and involves blood vessels (\"vascular). In stroke, arteries leading to and within the brain are either blocked by a clot or rupture. The end result is lack of oxygen and nutrients to the brain leading to brain damage. \n",
    "\n",
    "\n",
    "<img width=\"500\" height=300 src=\"https://www.strokeinfo.org/wp-content/uploads/2019/06/HTN_16_pg39_art600x400.png\">\n",
    "\n",
    "\n",
    "Stroke is usually diagnosed clinically (by symptoms) and imaging (non-contrast head CT scan). Stroke can exhibit a wide range of symptoms depending on the location affected within the brain. Some nonspecific symptoms include headache (\"worst headache of my life\", nausea, vomiting, loss of consciousness, and neck stiffness. If suspected a non-contrast head CT is ordered to detect bleeding. Depending on whether the stroke is caused by a clot or rupture, treatment will be different. A clot will be treated with blood thinners. A rupture will be treated through emergent neurosurgery. \n",
    "\n",
    "> Stroke require prompt diagnosis and treatment before irreversible damages sets in. Any tool (such as a predictive model) that could make stroke diagnosis quicker or easier could make a large difference in preventing stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using Jupyter Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To run any of the code, select the code cell on the **bottom right (1.2)**, and click the `Run` button on the toolbar above. Try it out on the example code cell below on the **bottom right (1.2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "source": [
    "**The** `Run` **Button**\n",
    "<img src=\"https://i.imgur.com/jr4dpLW.png\" style=\"width:300px;height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is an example of a code cell\n",
    "cat('Congratulations! \\n')\n",
    "cat('You\\'ve run your first code cell.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Jupyter Notebook Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is a Jupyter Notebook? Why is it so special? Below is a definition of Jupyter Notebook from the creators. \n",
    "\n",
    "> \"The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\" - [jupyter.org](https://www.jupyter.org)\n",
    "\n",
    "Through integrating code, text, and multimedia, jupyter notebooks allow us to create a digital notebook that is both **interactive** and **informative**. Don't just take my word for it though, personally explore how Jupyter Notebook can augment your learning through the case!\n",
    "\n",
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/1-LPnY8nOLg4S6_TG0DEXwsg-1.png\" style=\"width:600px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Case Code Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Within code cells you will see green text preceded by a `#` symbol. These are comments and will help explain what portions of the code are doing. All code should be ready to run as shown. \n",
    "\n",
    "Some code may require more time to run. On the left hand side you will notice the label: `In [ ]:`. If there is an `*` in between the `[]`'s after you select `Run`, that indicates that your code is in the process of running. Like so: `In [*]:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Meeting Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll be using a deidentified set of patient data made available on [kaggle](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1), a data science community website. The data was originally provided by Mckinsey Analytics for a online hackathon hosted by Analytics Vidhya.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p style=\"text-align: center;\">stroke_predict.csv</p>\n",
    "\n",
    "***\n",
    "This file contains our dataset. There are a little over 43,000 patients with 12 variables. The data includes general demographic and clinical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset will already be downloaded for the case. The The original data can be acceded [here](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Consulting the Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are several variables or labels which you might not understand. There are many reasons for this. You might lack domain experience for the data you're analyzing. The data creators might also have used arbitrary labels only they understood (this is considered a bad practice).\n",
    "\n",
    "The way to combat this is by consulting the data dictionary or documentation. These are tables or documents which describe the data in detail. Have a variable you don't understand? Check the documentation! Don't understand what an output for a variable means? Check the documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A data dictionary is provided on the [kaggle page](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data/version/1#Screen%20Shot%202018-04-17%20at%2012.15.42%20AM.png) where the data is hosted. The data dictionary has also been reproduced below for your convenience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Variable*        | *Definition*                                           |\n",
    "| ----------------- | ------------------------------------------------------ |\n",
    "| id                | Patient ID                                             |\n",
    "| gender            | Gender of Patient                                      |\n",
    "| age               | Age of Patient                                         | \n",
    "| hypertension      | 0 - no hypertension, 1 - suffering from hypertension   |\n",
    "| heart_disease     | 0 - no heart disease, 1 - suffering from heart disease |\n",
    "| ever_married      | Yes/No                                                 |\n",
    "| work_type         | Type of occupation                                     |\n",
    "| Residence_type    | Area type of residence (Urban/ Rural                   |\n",
    "| avg_glucose_level | Average Glucose level (measured after meal)            |\n",
    "| bmi               | Body mass index                                        |\n",
    "| smoking_status    | patient's smoking status                               |\n",
    "| stroke            | patient's smoking status                               |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup (Do Not Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the code below to set up specific settings for our case. Do not skip this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Increase max number of columns displayed in output tables\n",
    "options(repr.matrix.max.cols = 2000)\n",
    "set.seed(10) # Make sure your ML results are the same\n",
    "# Calling external libraries for additional functionality\n",
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(randomForest))\n",
    "suppressMessages(library(forcats))\n",
    "suppressMessages(library(cowplot))\n",
    "suppressMessages(library(caret))\n",
    "suppressMessages(library(e1071))\n",
    "suppressMessages(library(pROC))\n",
    "\n",
    "cat('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cleaning Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first step in any analytic project is to clean our data. This is a critical step that is commonly overlooked within data science projects. This is critical for making our data convenient to interpret and manipulate. In addition, many analytic techniques require properly formatted data. Healthcare datasets may also have data that isn't clinically relevant (ie. raw lab values). Processing can convert these variables into clinically meaningful information. It won't matter how sophisticated our analysis is if we don't properly process our data. A common saying in data science is \"Junk in, Junk out\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Reading Our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll begin by reading in our data so we can clean and use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "tags": [
     "#read_data",
     "=>setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Note: Unicode Transformation Format – 8 (UTF-8) is a standard to encode characters in different languages\n",
    "cat('Data loading, please wait\\n')\n",
    "stroke_data <- read.csv(file=\"data/stroke_predict.csv\",  encoding=\"UTF-8\", header=TRUE, sep=\",\")\n",
    "cat('Data loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's get an overview of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean1",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "head(stroke_data)\n",
    "str(stroke_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Take a minute to look over the output. The first output is the first few rows of our data. The second output give the structure of our data which includes variable name and the type of variable it is. We can see that many variables have not been coded into an easily human-readable format (ie. `hypertension`, `heart_disease`, `stroke`). We will also need to convert some of the clinical variables into meaningful categories (`avg_glucose_level` and `bmi`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Recoding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our first task will be recoding the variables `hypertension` (high blood pressure), `heart_disease`, and `stroke` into something meaningful. Based upon the data dictionary, we can see that a value of `1` for any of these fields indicates the patient is suffering from this condition. A value of `0` indicates they are not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean2",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "# Recoding\n",
    "stroke_data$hypertension[stroke_data$hypertension == 1] <- 'History of hypertension'\n",
    "stroke_data$hypertension[stroke_data$hypertension == 0] <- 'No hypertension'\n",
    "stroke_data$heart_disease[stroke_data$heart_disease == 1] <- 'History of heart disease'\n",
    "stroke_data$heart_disease[stroke_data$heart_disease == 0] <- 'No heart disease'\n",
    "stroke_data$stroke[stroke_data$stroke == 1] <- 'History of stroke'\n",
    "stroke_data$stroke[stroke_data$stroke == 0] <- 'No stroke'\n",
    "cat('Data Recoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean3",
     "=>clean2"
    ]
   },
   "outputs": [],
   "source": [
    "head(stroke_data[c('hypertension', 'heart_disease', 'stroke')])\n",
    "str(stroke_data[c('hypertension', 'heart_disease', 'stroke')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks like our changes were successful. In the output, notice the `chr`. This is R's way to tell us that R considers these as character variables. This just means R considers this a text or 'string' variable. The majority of variable you encounter in a an analysis will likely be numeric or categorical variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is the difference between a numeric and categorical variable? What kind of variable should we convert our three variables above into?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "- **Numeric:** variables whose values are whole numbers (ie. numbers, percents)\n",
    "- **Categorical:** variables whose values are selected from a group (ie. dog breeds, male/female) \n",
    "\n",
    "We should convert these variables into categorical variables because these variables have only a limited number of categories. \n",
    "\n",
    "> Note R calls categorical variables **Factors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean4",
     "=>clean2"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data$hypertension <- as.factor(stroke_data$hypertension)\n",
    "stroke_data$heart_disease <- as.factor(stroke_data$heart_disease)\n",
    "stroke_data$stroke <- as.factor(stroke_data$stroke)\n",
    "\n",
    "cat('Conversion complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It important to make sure your variables are encoded correctly in an analysis. Incorrectly encoded variables can ultimately affect the results of any predictive models or analysis you produce leading to faulty conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Why is checking for missing data important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Missing data can produce biased results or lead to lead to reduced statistical power of our analysis (by reducing our sample size)\n",
    "\n",
    "Missing data are a common feature of messy, real-world data. How you choose to deal with missing data will have a big impact on your analysis and any predictive model you build. There are several ways to deal with missing data such as removing or imputing missing data. More details on handling missing data in R can be found [here](https://www.r-bloggers.com/missing-value-treatment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let examine our data for missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean5",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "cat('Number of Missing Data for Each Variable:')\n",
    "sapply(stroke_data, function(x) sum(is.na(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Besides `bmi` our data looks exceptionally clean. This rarely happens. It is more likely that our data is not coded correctly. Lets examine our data more closely. Keep in mind R classifies missing `Na`. Look for odd symbols that R may not be registering as missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean6",
     "=>clean4"
    ]
   },
   "outputs": [],
   "source": [
    "head(stroke_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that `smoking_status` has numerous blank values. However, none of these are coded as missing (R recognizes miss as `Na` values). Lets take a closer look at `smoking_status`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean7",
     "=>read_data"
    ]
   },
   "outputs": [],
   "source": [
    "table(stroke_data$smoking_status, exclude = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that approximately 1/4 of `smoking status` values are blank! Lets make sure R can recognize these values as missing now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean8",
     "=>clean4"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data[stroke_data == ''] <- NA\n",
    "table(stroke_data$smoking_status, exclude = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Much better! Keep in mind different dataset encode missing or abnormal values differently. Even different programming languages encode missing values in their unique way. You need to watch out for these differences whenever dealing with a new dataset or tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Checking for Implausible Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets check our data for implausible values. Focus on the minimum and maximum values for the numeric output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean9",
     "=>clean8"
    ]
   },
   "outputs": [],
   "source": [
    "summary(stroke_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Among our variables, we can see that `bmi` has a maximum 97.60. It biologically unlikely for an individual to have a `bmi` of 97.60. Lets take a closer look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#clean10",
     "=>clean8"
    ]
   },
   "outputs": [],
   "source": [
    "cat('BMI:')\n",
    "quantile(stroke_data$bmi, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1), na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that the the max `bmi` is a huge jump even compared to our 99th percentile. However, a `bmi` of 10.1, while underweight, is physiologically possible. Based on our finding, lets reclassify implausible values as `Na`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean11",
     "=>clean8"
    ]
   },
   "outputs": [],
   "source": [
    "stroke_data$bmi[stroke_data$bmi > 60] <- NA\n",
    "\n",
    "cat('Values Reclassified!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Creating Clinically Relevant Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our data includes two clinical measures: `avg_glucose_lvl` and `bmi`. As raw alb values, these variables do not provide useful information. Adding context can help with this. Creating clinically relevant variables will help us better communicate and understand how these variables affect our outcome (stroke status). We will be taking these measures and creating clinically meaningful variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI stands for Body Mass Index. This a measure of body weight based upon a person's weight and height. This measure is commonly used to evaluate whether a person is overweight. Below is the BMI formula. \n",
    "\n",
    "\\[\\large \\frac{weight (kg)}{[height (m)]^{2}}\\]\n",
    "\n",
    "We will create a new variable which reflects the clinical cutoffs for bmi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the clinical cut-offs for BMI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *BMI Range*     |\n",
    "| -------------- | --------------- |\n",
    "| Underweight    | BMI < 18.5      |\n",
    "| Healthy Weight | 18.5 ≤ BMI < 25 |\n",
    "| Overweight     | 25 ≤ BMI < 30   |\n",
    "| Obese          | 30 ≥ BMI        |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let create the new variable `bmi_interp` based off these cut-offs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean12",
     "=>clean11"
    ]
   },
   "outputs": [],
   "source": [
    "# Create 'bmi_interp'\n",
    "stroke_data <- mutate(stroke_data, bmi_interp = ifelse(bmi < 18.5, 'Underweight', \n",
    "                                        ifelse(bmi >= 18.5 & bmi < 25, 'Healthy Weight',\n",
    "                                              ifelse(bmi >= 25 & bmi < 30, 'Overweight',\n",
    "                                                    ifelse(bmi >= 30, 'Obese', NA)))))\n",
    "\n",
    "# Convert from character to categorical\n",
    "# Make sure is ordered\n",
    "stroke_data$bmi_interp <- factor(stroke_data$bmi_interp, levels = c('Underweight', 'Healthy Weight',\n",
    "                                                                   'Overweight', 'Obese'), ordered = TRUE)\n",
    "\n",
    "cat('\\'bmi_interp\\' variable created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean13",
     "=>clean12"
    ]
   },
   "outputs": [],
   "source": [
    "head(stroke_data[c('bmi', 'bmi_interp')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Limitations and Considerations when using BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI is a simple, inexpensive, and common measure for body fat. However, there are several clinical considerations to keep in mind when using this measure. It's critical to keep in mind BMI is only a surrogate measure since it uses weight instead of actual body fat content in its calculations. Below are three examples of factors that can influence BMI:\n",
    "\n",
    "- Age: older adults usually have more body fat than younger adults for the same BMI\n",
    "- Gender: women tend to have greater amounts of body fat compared to men for the same BMI\n",
    "- Muscle mass: muscular individuals or athletes may have higher BMI due to increased muscle mass\n",
    "\n",
    "[Source](https://www.cdc.gov/obesity/downloads/bmiforpactitioners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Average Glucose Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The data dictionary defines `avg_glucose_lvl` as the average glucose level measured after meals (glucose is another term for blood sugar levels). Glucose levels are commonly used to assess whether a patient has diabetes. A patient with diabetes will have on-average a higher blood glucose level.\n",
    "\n",
    "However, `avg_glucose_lvl`, as defined by the data dictionary, is clinically problematic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Food for Thought:** What's wrong with 'avg_glucose_lvl' as a measure of blood glucose levels? What is a better measure of average blood sugar status?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Individual's blood glucose can vary widely day to day. This is especially true after meals when individuals are experiencing a physiological spike in their glucose levels. \n",
    "\n",
    "[Here's a news article discussing inter-population variability in glucose measurements](https://www.medicalnewstoday.com/articles/322614.php)\n",
    "\n",
    "A better measure would be hemoglobin A1C which measures the amount of sugar attached to each red blood cell. This is an indication of the average blood glucose status of a patient over 2 to 3 months. \n",
    "\n",
    "<img src=\"https://www.ekfdiagnostics.com/res/HbA1c-Hemoglobin-banner\" style=\"text-align: center; width: 66%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can't change the measurements used in the data. However, just because the glucose measurement is not ideal doesn't mean we need to disregard it completely. Every bit of data counts in analytics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A good proxy for `avg_glucose_level` would be the cutoffs determined by the oral glucose tolerance test (OGTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the criteria for normal, prediabetic, and diabetic in the OGTT two hours after drinking?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *Blood Glucose (mg/dl)*   |\n",
    "| -------------- | ------------------------- |\n",
    "| Diabetic       | 200 ≤ Blood Glucose       |\n",
    "| Prediabetic    | 140 ≤ Blood Glucose < 200 |\n",
    "| Healthy        |  Blood Glucose < 140      |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now use these criteria to classify a patient's 'avg_glucose_level' as either normal, prediabetic, or diabetic based upon OGTT criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean14",
     "=>clean12"
    ]
   },
   "outputs": [],
   "source": [
    "# Create 'diabetic_interp'\n",
    "stroke_data <- mutate(stroke_data, \n",
    "                      diabetic_interp = ifelse(avg_glucose_level < 140, 'Healthy', \n",
    "                          ifelse(avg_glucose_level >= 140 & avg_glucose_level < 200, 'Prediabetic',\n",
    "                              ifelse(avg_glucose_level >= 200, 'Diabetic', NA))))\n",
    "\n",
    "# Convert from character to categorical\n",
    "stroke_data$diabetic_interp <- factor(stroke_data$diabetic_interp, \n",
    "                                      levels = c('Healthy', 'Prediabetic', 'Diabetic'),\n",
    "                                      ordered = TRUE)\n",
    "\n",
    "cat('\\'diabetic_interp\\' variable created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#clean15",
     "=>clean14"
    ]
   },
   "outputs": [],
   "source": [
    "head(stroke_data[c('avg_glucose_level', 'diabetic_interp')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This section was an important demonstration about how to utilize domain knowledge when processing your data (referred to as feature engineering by the machine learning community). Almost all analytic project will require you to communicate results to non-technical stakeholders. Creating domain specific variables, such as we did, is a critical part to helping other understand your results and analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've cleaned our data we can begin exploring our data. Using this, we can see which variables (features) are good candidates for building our prediction model. Feature selection  will determine how good or how bad your model is. Bad feature selection can have a negative impact on your model even if you used the most advanced techniques. Understanding the clinical nuances of your data can inform better feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Why Can't We Just Use All or Most Variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One issue you might be wondering about is why do we even need to select variables. Why not just use all of the variables? After all, more data lead to better models right? This is a common misconception that even experienced analysts need to watch out for. Including too many features in your prediction model can lead to what is known as **overfitting**.\n",
    "\n",
    "<img src=\"https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1527613915658.png\" align=\"center\" style=\"width: 50%; margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    " **Overfitting** is essentially where you build a model that adheres too closely to your current data set and is unable to predict observations that are not from your current data set. In other words, its where you develop a model that tuned too closely to your current data, and is not generalizable to outside data sources. A prediction model that is not generalizeable is not a useful model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Getting A Closer Look At Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets take a closer look as we begin our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA1",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "str(stroke_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA2",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "summary(stroke_data[,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This second output presents us with quite a bit of data. The first thing to realize is that the output will differ based on whether the variable is numeric or categorical. Numeric outputs will include summary statistics while categorical variables will include frequency counts of each category. \n",
    "\n",
    "These summaries will provide a useful reference throughout our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first indicator of whether a variable would be a good candidate for being a variable for our prediction model is the number of missing values. \n",
    "\n",
    "Among the categorical variables, the only variable with a significant amount of missing data is `smoking_status`.\n",
    "\n",
    "There are varying interpretations of what constitutes a significant amount of missing data. For our purpose we will consider any variable with >10% of its values missing as having a significant number of missing observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** Why is using variables with significant amounts of missing data problematic for making predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Missing data can bias the results of our analysis. For instance, say that the individuals that did not respond about smoking status refused to respond because they were embarrassed of their smoking habit. This might make smoking individuals more likely to be smokers compared to individuals that responded to the survey. \n",
    "\n",
    "In summary, missing data can be problematic, especially if the missing group is somehow different from the non-missing group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The next step will then be to determine whether the data missing is simply the result of random chance or not. If the result is simply due to random chance, this is less problematic since it's less likely to bias our results. However, if missing values don't appear be due to random chance, this could lead to bias in our final analysis leading to a faulty prediction!\n",
    "\n",
    "When predicting something as serious as stroke, faulty predictions are the last thing we want. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets split our `smoking_status` variable into missing or not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA3",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "# Split Into Null or Not\n",
    "stroke_data <- mutate(stroke_data, smoke_miss = ifelse(smoking_status == 'NA', 'Missing', 'Not Missing'))\n",
    "stroke_data$smoke_miss <- invisible(fct_explicit_na(stroke_data$smoke_miss, na_level = 'Missing'))\n",
    "\n",
    "# Confirm results\n",
    "table(stroke_data$smoke_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can test whether the incidence of stroke differs significantly between individuals who responsed about smoking status and those who did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA4",
     "=>EDA3"
    ]
   },
   "outputs": [],
   "source": [
    "table(stroke_data$smoke_miss, stroke_data$stroke)\n",
    "chisq.test(stroke_data$stroke, stroke_data$smoke_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From our test results we can see the p-value is < 0.05. This indicates that there is a statistially significant difference between the missing and non-missing group according to `smoking_status`. \n",
    "\n",
    "This is unfortunate. Clinically, it has been well-documented that smoking can lead to increased incidence of cardiovascular disease and can increase the likelihood of stroke. However, our analysis indicates that including this data, which has so many missing data, would bias our model. Despite our clinical intuition suggesting smoking status would be a good candidate, the data is not robust enough to support a prediction model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** To check whether the missing or non-missing group differed we used a chi-squared test. What is a chi-squared test? Is a chi-squared test used for numeric or categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "A chi-square test is a statistical test that tells you whether groups of observations are different. For instance, say you're researching two companies and you divide them either as male or female. The number of males compared to females in the two companies differ but how can you tell that this is not random chance? A chi-squared test can be used to differentiate whether the **observed** number of males and females in your study differs from the **expected** number of males and females. \n",
    "\n",
    "> Note: Chi-square tests can only be used for categorical variables. There are separate tests to determine whether numerical numbers differ form one another. These additional tests are beyond the scope of the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Assessing Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets take a look at our other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA5",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "summary(stroke_data[,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Based on our output above what are the numeric feature(s) we would consider for our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "We can see that there are a couple numeric variables. However, the only one we would consider is `age`. While `bmi` and `avg_glucose_level` are both numeric variables, they both have newer and more clinically relevant variables available. Including both the raw lab values and the newer interpretation variables for these two would be redundant and could lead to overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have some summary statistics about age available. Lets take a look at the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA6",
     "=>read_data",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Plot\n",
    "age_plot <- ggplot(stroke_data, aes(x=age)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=30, color ='black ', fill='light blue') +\n",
    "labs(x='Age (years)', y='Frequency Count', caption = 'Dashed Line Represents Median Age')\n",
    "\n",
    "# Display + Median Line\n",
    "age_plot + geom_vline(aes(xintercept=median(age)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There does not appear to be any extreme age values or prominent age clusters. Now lets see if theres a relationship between stroke status and age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Do you expect there to be a relationship between stroke status and age? Why? Keep in mind your answer before seeing the output below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA7",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Plot\n",
    "violin_plot_age <- ggplot(stroke_data, aes(x=stroke, y=age, color = stroke, fill = stroke)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Age (years)', x='Stroke Status', \n",
    "     caption = 'The dots in the center of each violin plot represent median age of each group') +\n",
    "coord_flip()\n",
    "\n",
    "# Display Plot\n",
    "violin_plot_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Based on our results, does age have an effect on stroke status? What could explain our results? Do our results indicate age would be a good candidate variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "The results are pretty stark. Both median age and distribution of age drastically differs between the stroke and non-stroke group. As age increases, we can see the the distribution of strokes increases. This can likely be explained by the fact that individuals over the age of 55 are the most likely to have a stroke with stroke risk increasing as an individual ages further. This is because individual arteries become narrower and and stiffer with age increasing the risk of a cerebrovascular event. \n",
    "\n",
    "These results indicate age is an excellent candidate variable for our model since age seems to have a large effect on stroke status. This indicates our model could use age to differentiate between stroke and no stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally lets look at our remaining variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA8",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "str(stroke_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Based on our output, which variables are categorical and would we be exploring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Our variables of interest will be `gender`, `hypertension`, `heart_disease`, `ever_married`, `work_type`, `Residence_type`, `smoking_status`, `stroke`, `bmi_interp`, and `diabetic_interp`\n",
    "\n",
    "Remember R considers categorical variables as `Factor` variables. You may have noticed there is a category of ordered factors. This is a specific subtype of categorical variables where the order of categories is meaningful (ie. the order of our bmi categories is meaningful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let examine the effect our categorical variables have on stroke through using a stacked bar plot. Before continuing consider which variables you believe will have the largest effect and which will not. For instance, do you expect `hypertension` to have an effect. Do you expect it to have more of an effect than whether the individual had heart disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA9",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "p1 <- ggplot(stroke_data, aes(x=gender, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='Gender', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "p2 <- ggplot(stroke_data, aes(x=hypertension, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='Hypertension', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "p3 <- ggplot(stroke_data, aes(x=heart_disease, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='Heart Disease', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "p4 <- ggplot(stroke_data, aes(x=ever_married, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='Ever Married', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "p5 <- ggplot(stroke_data, aes(x=work_type, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='Work Type', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "p6 <- ggplot(stroke_data, aes(x=Residence_type, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='Residence Type', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "p7 <- ggplot(stroke_data, aes(x=bmi_interp, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='BMI', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "p8 <- ggplot(stroke_data, aes(x=diabetic_interp, fill = stroke)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='Diabetes Status', fill = \"Stroke Status\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "# Arrange plots into grid\n",
    "plot_grid(p1, p2, p3, p4, p6, p8, ncol = 2)\n",
    "plot_grid(p5, p7, ncol = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Based on our results, what variables seem to have an effect on stroke status? Does this make them good candidate variables for our prediction model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "This plot grid allows us to quickly see how stroke rates differ depending on variable. Based on observation it appears `hypertension`, `heart_disease`, `marriage_status`, `work _type`, `bmi_interp`, and `diabetes_interp` all seem to have an effect on stroke and seem to be promising candidate variables. \n",
    "\n",
    "Not surprisingly, having an associated comorbidity ( `hypertension`, `heart_disease`) has some of the largest effects on having a stroke. Both of these conditions are associated with cardiovascular disease cardiovascular disease (hypertension can damage arteries; heart disease will worsen arterial narrowing). Surprisingly, marriage status has a large effect on stroke as well. Perhaps individuals that are married are on average older or lead more sedentary lifestyles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now lets analyze our predictor variables. Logistic regression is a mathematical model that estimates the probability of a binary outcomes. It is named after the logistic curve which takes the S-shape depicted below.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png?1566122052688\" alt=\"Logistic Curve\" title=\"Logistic Curve\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is our outcome? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Our primary outcome is whether the individual had a stroke. \n",
    "\n",
    "The logistic regression model will allow us to see how individuals variables affect whether an individual has a stroke **while controlling for other variables in the model**. For instance, we can see whether being older affects having a stroke while controlling for diabetes, heart disease, etc..\n",
    "\n",
    "Very useful indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will be using logistic regression to assess whether our variables have a statistically significant effect on whether a person has a stroke. \n",
    "\n",
    "Statistical significance is how likely a relationship between variables in our data did not occur by chance. For example, if we find that age has a statistically significant effect on having a stroke, this means that this effect is more likely than chance alone would suggest. \n",
    "\n",
    "The conventional level of significance that is accepted is < 0.05 (this number is referred to as a p-value). This means that there is less than 5% chance that the observed relationship was due to chance alone. The image below display a sample R output with the p-value highlighted.\n",
    "\n",
    "<img src=\"https://drchrispook.files.wordpress.com/2017/02/anova-output-from-r1.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em; width: 75%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets create a logistic model using our chosen candidate predictor variables. Look at the p-value column to see whether our variables are statistically significant. Remember, we want our variables to have a p-value < 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#EDA10",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "# Creating a logistic regression model\n",
    "mylogit <- glm(stroke ~ age + hypertension + heart_disease + \n",
    "               ever_married + work_type + bmi_interp + diabetic_interp,\n",
    "               data = stroke_data, family = \"binomial\")\n",
    "mylogit.sum <- summary(mylogit)\n",
    "mylogit.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that several of our variables do not have a statistically significant effect (`work_type`, `ever_married`, and `bmi_interp`). This indicates that these variables may not be good candidate predictor variables. For this reason, we will not be using `work_type` and `ever_married`. However, we will be using `bmi_interp` because we know that clinically, metabolic factors have a significant effect on stroke risk. This is because many of causes of being overweight (ie. sedentary lifestyle and unhealthy diet) can lead to build up of plaques in arteries. This increases the risk for stroke. \n",
    "\n",
    "While statistical significance is important, it is always more important to consider whether our predictor are clinically relevant for the outcome we will be predicting. Remember to alway consider the clinical significance of a variable and not just the statistical significance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building a Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** So far we haven't done any machine learning yet. What we've done can be considered traditional statistical analyses. What differentiates machine learning from traditional statistical analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "In machine learning, data is split into a training and test set. A machine learning model is then trainined on the training set to predict whatever outcome of interest it was designed to predict (in our case we're predicting whether the patient will have a stroke). The models predictive performance is then evaluated using the test set. \n",
    "\n",
    "<img src=\"https://www.sqlservercentral.com/wp-content/uploads/2019/05/Image-2.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For our case, we will be using a model called a random forest. A random forest is an algorithm built from numerous smaller algorithm called decision trees. Decision trees are charts which help make a decision or prediction. Each branch represents a possible outcome. The end of branches represent an end result or decision. \n",
    "\n",
    "Decision trees are common in medical settings. For instance, below is an algorithm for evaluating febrile seizures. This is an example of a decision tree.\n",
    "\n",
    "<img src=\"https://img.grepmed.com/uploads/1105/febrileseizure-management-algorithm-diagnosis-complex-original.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a random forest algorithm, the results of hundreds (and even thousands) of decision trees are calculated. These results are all combined. \n",
    "\n",
    "The rationale is that while a single decision tree can easily be wrong, the pooled result from numerous trees will be more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets split our data into a training and test set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#ML1",
     "=>clean15"
    ]
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and test set data\n",
    "# Setting the seed value so we get the same result when we repreat\n",
    "set.seed(100)\n",
    "\n",
    "# Determining which rows willbe in the traiing data\n",
    "training_index <- sample(nrow(stroke_data), 0.8*nrow(stroke_data), replace = FALSE)  \n",
    "\n",
    "# Create Training Set\n",
    "training_data <- stroke_data[training_index,]\n",
    "\n",
    "# Create Test Set\n",
    "# Don't include stroke column in test set. Prediction will create this column. If you\n",
    "# include stroke variable, confusion matrix will throw an unequal lengths error\n",
    "test_data <- stroke_data[-training_index,]\n",
    "\n",
    "cat('Training and Test Data Created!')\n",
    "\n",
    "# Set up the model\n",
    "model <- (stroke ~ age + hypertension + heart_disease + bmi_interp\n",
    "         + diabetic_interp + smoking_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now lets fit our random forest model to the training and test data. We will then take a look at our models performance using a confusion matrix.\n",
    "\n",
    "> If you're unsure what a confusion matrix is, please consult section 5.0.1 ('What is a Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#ML2",
     "=>ML1"
    ]
   },
   "outputs": [],
   "source": [
    "# Add in NA action to exclude missing \n",
    "cat('Training Random Forest, please be patient...\\n')\n",
    "train_rf <- randomForest(formula = model, data = training_data, na.action=na.omit, importance = TRUE)\n",
    "\n",
    "# Predict\n",
    "cat('Testing Random Forest, please be patient...\\n')\n",
    "predict_rf <- predict(train_rf, newdata = test_data[,-12], # -12 removes stroke from predictors\n",
    "                      type = \"class\")\n",
    "                      \n",
    "# Output results\n",
    "cat('Outputing results...')\n",
    "confusionMatrix(data = predict_rf, reference = test_data$stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Do you notice anything strange about our model's performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "We see that our accuracy is over 90%. However, we did not correctly identify a single stroke. All this model could do is predict no strokes, the opposite of what we want!\n",
    "\n",
    "This is one of the weaknesses of random forests. Since the data is very imbalanced (ie. there are tons of negative results and only a few positive results), we can still maintain over 90% accuracy and not predict a single stroke. The algorithm is biased towards outcomes which maximizes its accuracy. \n",
    "\n",
    "We will be implementing a solution known as a weighted random forest. This will punish the algorithm more heavily for misclassifying the data. This is known as cost-sensitive learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#ML3",
     "=>ML1"
    ]
   },
   "outputs": [],
   "source": [
    "# Training new weighted Random Forest model\n",
    "cat('Training Random Forest, please be patient...\\n')\n",
    "weighted_rf <- randomForest(formula = model, data = training_data, na.action=na.omit, \n",
    "                            importance = TRUE, classwt=c(0.5, 0.5))\n",
    "\n",
    "# Testing new weighted Random Forest model\n",
    "cat('Testing Random Forest, please be patient...\\n')\n",
    "weighted_predict_rf <- predict(object = weighted_rf, newdata = test_data[-12], type = \"class\")\n",
    "\n",
    "# Outputting results\n",
    "cat('Outputing results...')\n",
    "confusionMatrix(data = weighted_predict_rf, reference = test_data$stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Much better! This illustrates why accuracy can be a misleading metric for machine learning models. So if accuracy is not a great measure, what is? Continue on to find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What Is A Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A confusion matrix is a 2x2 table which computes 4 different combinations of predicted vs. actual values. The combinations are True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/320/1*Z54JgbS4DUwWSknhDCvNTQ.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    "These 4 interpretations can be combined to generate many useful metrics. For our purpose there are three we will focus on. The first is accuracy: \n",
    "\n",
    "\\[\\large (TP + TN)/Total\\]\n",
    "\n",
    "Accuracy allows us to measure how often our model predicted correctly. The second metric is sensitivity:\n",
    "\n",
    "\\[\\large TP / (TP + FN)\\]\n",
    "\n",
    "Sensitivity asks the question, that when our outcome is actually positive (ie. in our case when our patient is actually high-risk) how often will the model predict positively (ie. how often will the model then predict the patient to be high-risk). The final metric is specificity:\n",
    "\n",
    "\\[\\large FP / (FP + TN)\\]\n",
    "\n",
    "Specificity asks the question, that when the outcome is actually negative (ie. in our case when our patient is actually low-risk) how often will the model predict negatively (ie. how often will the model then predict the patient to be low-risk). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will be evaluating our model using a receiver operating curve (ROC) and the area under the curve (AUC) value. \n",
    "\n",
    "> If you're unsure what a ROC or AUC value is, please consult section 5.1.1 ('Understanding ROC Curves and AUC Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#ML4",
     "=>ML3"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a ROC curve\n",
    "ROC <- roc(response = test_data$stroke, predictor = factor(weighted_predict_rf, \n",
    "                                                           ordered = TRUE, \n",
    "                                                           levels = c('No stroke', 'History of stroke')))\n",
    "\n",
    "# Plot ROC with ggplot2\n",
    "plot_ROC <- ggroc(ROC) + xlab('1 - Specificity') + ylab('Sensitivity')\n",
    "plot_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#ML5",
     "=>ML4"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the area under the curve (AUC)\n",
    "cat('AUC:', round(auc(ROC), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The closer to the top left corner our ROC curve is the better. The higher our AUC value is the better. The AUC value simply measures the area under our ROC curve. \n",
    "\n",
    "These metrics provide useful measures when tuning our model. They are also better overall measures than accuracy alone. We can compare different models using these two metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Understanding ROC Curves and AUC Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An ROC curve informs us about how good a model can classify between two outcomes (ie. if a patient has a disease or no disease).An ROC plots sensitivity (probability of predicting a true positive will be positive) against 1-specificity (the probability of predicting a real negative will be a positive). \n",
    "\n",
    "An ROC curve which hugs the top left corner indicate a model that can perfectly distinguishes between two outcomes. A model with a 50-50 chance of making a correct decision will have a ROC curve which is just a diagonal line. \n",
    "\n",
    "The area under a curve is a measure of magnitude of the ROC curve. The closer the ROC curve is to the top left corner, the higher the AUC value is. The higher the AUC value is, the better our prediction model is. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/406/1*pk05QGzoWhCgRiiFbz-oKQ.png\" style=\"float: center; width: 34%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Explaining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important part of any model is being able to explain it. One way we can exaplain our model is variable importance. This measures how much our given model uses a specific variable to make accurate predictions. Based on our results, which variables do you think will be the most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": [
     "#ML6",
     "=>ML3"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Dataframe\n",
    "imp <- cbind.data.frame(Feature=rownames(weighted_rf$importance), weighted_rf$importance)\n",
    "\n",
    "# Create Plot\n",
    "gini <- ggplot(imp, aes(x=reorder(Feature, MeanDecreaseGini), y=MeanDecreaseGini))\n",
    "\n",
    "# Display Plot\n",
    "gini + geom_bar(stat = 'identity') + xlab('Feature') + ylab('Variable Importance') + coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From our model we can see that age is by far the most important variable for performance. This makes sense since the risk for stroke is dramatically higher in the elderly due to arterial narrowing and stiffening. We can see that our other variables are roughly similar in importance for our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Congratulations! You've reached the end of the case! This case provided just one example of how analytics and healthcare can be combined to solve clinical problems. I hope your curiosity has been piqued. There much more to learn and much more you can explore in this field!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "414px",
    "left": "54px",
    "top": "110.8px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.4px",
    "left": "432px",
    "right": "20px",
    "top": "129px",
    "width": "542.925px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
