{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p align=\"justify\">Welcome! In this case we'll be exploring how to use advanced analytic and machine learning techniques to predict diabetes among the Pima Indian population. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Some of the skills you'll explore are (Click to Expand):</summary>\n",
    "<ul>\n",
    "    <li>R Programming</li>\n",
    "    <li>Data Cleaning</li>\n",
    "    <li>Exploratory Data Analysis</li>\n",
    "    <li>Data Visualization</li>\n",
    "    <li>Leveraging Domain Knowledge</li>\n",
    "    <li>Machine Learning</li>\n",
    "    <li>Gradient Boosting Machines</li>\n",
    "</details><br>\n",
    "Don't worry if you're unsure what some of these terms are. They'll be explained throughout the case. Let's begin! \n",
    "<img src=\"https://i.stack.imgur.com/zlAi2.png\" style=\"float: left; width: 33%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://cdn.images.express.co.uk/img/dynamic/11/590x/Diabetes-symptoms-870995.jpg\" style=\"float: left; width: 35%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://46gyn61z4i0t1u1pnq2bbk2e-wpengine.netdna-ssl.com/wp-content/uploads/2018/11/sankey-diagram-1.png\" style=\"float: left; width: 28%; margin-left: 1%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "## Case Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine you're a program officer for the Indian Health Service (IHS). Your state has recently obtained a federal grant aimed at improving health equity. This includes improving care among traditionally disadvantaged groups. From working within the IHS for several years now, you know that American Indians are more likely to suffer from metabolic diseases, particularly diabetes. \n",
    "\n",
    "<img width=\"500\" height=325 src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Indian_Health_Service_Logo.svg/1200px-Indian_Health_Service_Logo.svg.png\">\n",
    "\n",
    "With this grant, you now have the chance to leverage new technologies in analytics and machine learning to improve care among this group. If you can predict diabetes in patients before it manifests symptomatically, you can target preventative services toward this population\n",
    "\n",
    "Continue the case to find out how"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra: What is Diabetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Diabetes describes a group of metabolic disorders that is characterized by abnormally high blood glucose (blood sugar). Insulin is a critical hormone that allows the body to take up glucose and use it as energy. Diabetes occurs when your body does not produce enough insulin or cannot use insulin well. When this happens, glucose stays in your blood instead of being used as energy. Over time, this glucose in your blood can lead to various health problems. These can include serious complications such as blindness, limb amputation, and stroke. \n",
    "\n",
    "<img src=\"http://cdn.shopify.com/s/files/1/0582/0445/files/blood-sugar-levels-and-paleo_diagram_of_excessive_blood_glucose.jpg?14686865159083212781\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    "Diabetes is common among individuals over 45 years old, have a family history of diabetes, and are overweight. Poor lifestyle choices such as not exercising or smoking can also increase the risk. Diabetes is one of the most common conditions in the United States with over 30 million people suffering from diabetes. The total estimated cost of diabetes to the health care system is estimated to be $327 Billion. Current treatment includes insulin and medication to control blood glucose levels. Lifestyle modifications before the onset of diabetes can make a huge difference in whether a person develops diabetes. Any algorithm which could reliably predict diabetes could give providers critical information to intervene before a patient has diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## How To Run The Case (Do Not Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we begin the case, we need to know how to use Jupyter Notebook and run the case. First, look for the the `Run` button. The location of the `Run` button is shown below and can be found in the tool bar above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "\n",
    "<img src=\"https://i.imgur.com/jr4dpLW.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The cell below is a code cell. You will be running numerous code cells like the one below throughout the case. Select the cell and select the run button above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:22.351853Z",
     "start_time": "2020-03-17T01:42:22.297Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is an example of a code cell\n",
    "cat('Congratulations! \\n')\n",
    "cat('You\\'ve run your first code cell.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width = 50 height = 50 style=\"float: left; margin-right: 10px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/Stop_sign_dark_red.svg\">Stop! If you have not learned to run a code cell, restart this section. You will not be able to go through the case at all if you are unable to run code cells. Otherwise, it's time to meet our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Meeting Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll be using a set of patient data made available by the National Institute of Diabetes and Digestive and Kidney Diseases. It's important to note that several constraints were made in order to acquire the dataset. All patients are female, at least 21 years old, and of Pima Indian heritage. The variables selected were chosen due to being significant risk factors for diabetes among Pimas or other population groups. The data is hosted on [kaggle](https://www.kaggle.com/uciml/pima-indians-diabetes-database), a data science community website. \n",
    "\n",
    "**Acknowledgements** <br>\n",
    "Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data First Look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets get a first glimpse of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:23.062977Z",
     "start_time": "2020-03-17T01:42:22.984Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pima_diabetes <- read.csv(file=\"data/diabetes.csv\",  encoding=\"UTF-8\", header=TRUE, sep=\",\")\n",
    "head(pima_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What do you notice? Do you notice anything unusual about the data? Don't worry if you don't notice anything. We will be getting to know our data better as we go through the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data Variable Information (Consulting the Data Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are several variables or labels which you might not understand. The way to combat this is by consulting the data dictionary. \n",
    "\n",
    "> A data dictionary describes a dataset and provides information on the meaning of each variable. Always look for documentation or a data dictionary before starting an analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unfortunately, no documentation is provided on the original data page. However, the original study the data comes from is available [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/pdf/procascamc00018-0276.pdf). The relevant information has been added below for your convenience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Variable*               | *Definition*                                                         |\n",
    "| ------------------------ | -------------------------------------------------------------------- |\n",
    "| Pregnancies              | Number of times pregnant                                             |\n",
    "| Glucose                  | Plasma glucose concentration following a 2 hour oral glucose tolerance test                                             |\n",
    "| BloodPressure            | Diastolic Blood Pressure (mm Hg)                                     | \n",
    "| SkinThickness            | Triceps Skin Fold Thickness (mm)                                     |\n",
    "| Insulin                  | 2-Hour Serum Insulin Levels                                          |\n",
    "| BMI                      | Weight in kg / (Heigh in m)^2                                        |\n",
    "| DiabetesPedigreeFunction | Measure of expected genetic influence on the subject's diabetes risk |\n",
    "| Age                      | Age (Years)                                                          |\n",
    "| Outcome                  | Diabetes as defined as plasma glucose concentration > 200 mg/dl two hours after ingestion of 75 gram carbohydrate solution |\n",
    "\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup (Do Not Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the code below to set up specific settings for our case. Do not skip this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:24.714907Z",
     "start_time": "2020-03-17T01:42:24.559Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Increase max number of columns displayed in output tables\n",
    "options(repr.matrix.max.cols = 50)\n",
    "set.seed(10) # Make sure your ML results are the same\n",
    "\n",
    "# Calling external libraries for additional functionality\n",
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(randomForest))\n",
    "suppressMessages(library(forcats))\n",
    "suppressMessages(library(cowplot))\n",
    "suppressMessages(library(caret))\n",
    "suppressMessages(library(e1071))\n",
    "suppressMessages(library(pROC))\n",
    "suppressMessages(library(mice))\n",
    "suppressMessages(library(gbm))\n",
    "\n",
    "# Create function to test models\n",
    "test_model <- function(features){\n",
    "    # Set up the model\n",
    "    total_variables <- append(features,\"Outcome\")\n",
    "    play_trainingData <- subset(training_data,select = total_variables)\n",
    "    play_testData <- subset(test_data,select = total_variables)\n",
    "    # Add in NA action to exclude missing \n",
    "    model_gbm <- train(Outcome~., data=play_trainingData, method=\"gbm\", na.action = na.omit,verbose=FALSE)\n",
    "\n",
    "    # Predict\n",
    "    prediction_gbm <- predict(model_gbm, play_testData)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm <- confusionMatrix(prediction_gbm, play_testData$Outcome)\n",
    "    print(cm)\n",
    "    # Create a ROC curve\n",
    "    ROC <- roc(response = play_testData$Outcome, predictor = factor(prediction_gbm, \n",
    "                                                               ordered = TRUE))\n",
    "\n",
    "    # Plot ROC with ggplot2\n",
    "    plot_ROC <- ggroc(ROC)\n",
    "    print(plot_ROC)\n",
    "    cat('AUC:', round(auc(ROC), 2),'\\n')\n",
    "    test <- varImp(model_gbm)\n",
    "    ggplot(test)\n",
    "    }\n",
    "\n",
    "cat('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cleaning Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first step in any analytic project is to clean our data. This is a critical step that is commonly overlooked within data science projects. This is critical for making our data convenient to interpreted and manipulated. In addition, many analytic techniques require properly formatted data. Finally, healthcare datasets may have data that isn't clinically relevant (ie. raw lab values). Processing can convert these variables into clinically meaningful information. It won't matter how sophisticated our analysis is if we don't properly process our data. A common saying in data science is \"Junk in, Junk out\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inspecting Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll read in our data so we can clean and use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:25.763064Z",
     "start_time": "2020-03-17T01:42:25.677Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note: Unicode Transformation Format – 8 (UTF-8) is a standard to encode characters in different languages\n",
    "cat('Data loading, please wait\\n')\n",
    "pima_diabetes <- read.csv(file=\"data/diabetes.csv\",  encoding=\"UTF-8\", header=TRUE, sep=\",\")\n",
    "cat('Data loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's get an overview of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:26.026001Z",
     "start_time": "2020-03-17T01:42:25.910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head(pima_diabetes)\n",
    "str(pima_diabetes)\n",
    "summary(pima_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the most part all values are classified correctly as numeric or categorical besides the `Outcome` variable.  In addition there seem to be some odd values. There are individuals with a `BMI` of 0 or 67.1, likely implausible values. Other instances of implausible values include a `Glucose` of 0, 17 `Pregnancies`, and `SkinThickness` of 99 mm. We will consider all of these characteristics as we clean our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Recoding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First let's recode the variable `Outcome`into something meaningful. Based upon the data dictionary, we can see that `1` indicates the patient is classified as having Diabetes. `0` indicates they are not classified as having diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:26.517393Z",
     "start_time": "2020-03-17T01:42:26.460Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Recoding\n",
    "pima_diabetes$Outcome <- ifelse(pima_diabetes$Outcome == 1, 'Diabetes', \n",
    "                               ifelse(pima_diabetes$Outcome == 0, 'No diabetes', NA))\n",
    "\n",
    "# Convert from character to factor\n",
    "pima_diabetes$Outcome <- as.factor(pima_diabetes$Outcome)\n",
    "cat('Data Recoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:26.657957Z",
     "start_time": "2020-03-17T01:42:26.597Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(pima_diabetes[c('Outcome')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's examine the number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:27.327745Z",
     "start_time": "2020-03-17T01:42:27.256Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat('Number of Missing Data for Each Variable:')\n",
    "sapply(pima_diabetes, function(x) sum(is.na(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is very interesting. There are no missing values. If this is true, then this is an incredibly clean dataset. However, this is rarely the case. It's more likely that R cannot recognize missing or erroneous values as being missing. \n",
    "\n",
    "All of our variables are numeric so it is unlikely there will be categories of erroneously coded data. The more likely option is that there are implausible values. This will increase our number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Removing Implausible Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Earlier we saw several implausible values. These include `Glucose`, `BloodPressure`, `SkinThickness`, `Pregnancies`, `Insulin`, and `BMI`. Lets take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:28.062276Z",
     "start_time": "2020-03-17T01:42:27.886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat('Glucose:')\n",
    "quantile(pima_diabetes$Glucose, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Blood Pressure:')\n",
    "quantile(pima_diabetes$BloodPressure, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Skin Thickness:')\n",
    "quantile(pima_diabetes$SkinThickness, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Serum Insulin:')\n",
    "quantile(pima_diabetes$Insulin, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('BMI:')\n",
    "quantile(pima_diabetes$BMI, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Pregnancies')\n",
    "quantile(pima_diabetes$Pregnancies, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on the percentiles above, we can get a better sense of implausible and plausible values. Based on the results we can make the following judgements:\n",
    "\n",
    "**Glucose:**\n",
    "- Glucose is unlikely to go below 50 with the 1st percentile being 57. The 0 glucose measurement is physiologically impossible and likely to be an error or missing\n",
    "\n",
    "**Blood Pressure:**\n",
    "- Diastolic blood pressure is unlikely to go below 30 with the 5th percentile being 38.7. Patients at this level are likely to be considered hypotensive or in shock. 0 diastolic blood pressure is physiologically impossible and likely to be an error or missing.\n",
    "\n",
    "**Skin Thickness:**\n",
    "-  It is biologically unlikely that skin thickness would be above 80 mm or below 10 mm. This is confirmed by our percentile data with a huge jump between the 99th and 100th percentile. \n",
    "\n",
    "**Serum Insulin:**\n",
    "-  2 hour serum insulin levels are physiologically unlikely to fall below 10 or above 300. This is confirmed by our percentile results. The jump from 95th to 99th and 100th percentile is enormous. In addition the values 0 for serum insulin are physiologically impossible and likely errors. \n",
    "\n",
    "**BMI:**\n",
    "- BMI is unlikely to go above the 99th percentile of 50.759. The maximum of 67.1 seems biologically implausible. \n",
    "- BMI below the 5th percentile of 21.8 are possible. However, BMI values of 0 are likely mistakes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on these findings, let's reclassify implausible values as `Na`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:28.331107Z",
     "start_time": "2020-03-17T01:42:28.243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pima_diabetes$Glucose[pima_diabetes$Glucose < 50] <- NA\n",
    "pima_diabetes$BloodPressure[pima_diabetes$BloodPressure < 30] <- NA\n",
    "pima_diabetes$SkinThickness[pima_diabetes$SkinThickness < 10 | pima_diabetes$SkinThickness > 80] <- NA\n",
    "pima_diabetes$Insulin[pima_diabetes$Insulin < 10 | pima_diabetes$Insulin > 500] <- NA\n",
    "pima_diabetes$BMI[pima_diabetes$BMI < 10 | pima_diabetes$BMI > 50] <- NA\n",
    "\n",
    "cat('Data Recoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets recheck our missing measurements now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:28.564821Z",
     "start_time": "2020-03-17T01:42:28.446Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat('Number of Missing Data for Each Variable:')\n",
    "sapply(pima_diabetes, function(x) sum(is.na(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "While our data is not as clean, this is a more realistic result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Creating Clinically Relevant Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our data includes the raw lab values for BMI. This is not a very useful measure by itself. Let's convert it into something more clinically meaningful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Quantitative:** variables whose values are whole numbers (ie. numbers, percents)\n",
    "- **Categorical:** variables whose values are selected from a group (ie. dog breeds, male/female) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI stands for Body Mass Index. This is a measure of body weight based upon a person's weight and height. This measure is commonly used to classify individuals as being overweight or a healthy weight. Below is the BMI formula. \n",
    "\n",
    "\\[\\large \\frac{weight (kg)}{[height (m)]^{2}}\\]\n",
    "\n",
    "We will create a new variable which reflects the clinical cutoffs for bmi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the clinical cut-offs for BMI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *BMI Range*     |\n",
    "| -------------- | --------------- |\n",
    "| Underweight    | BMI < 18.5      |\n",
    "| Healthy Weight | 18.5 ≤ BMI < 25 |\n",
    "| Overweight     | 25 ≤ BMI < 30   |\n",
    "| Obese          | 30 ≥ BMI        |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let create the new variable 'bmi_interp' based on these cut-offs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:29.896843Z",
     "start_time": "2020-03-17T01:42:29.819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create 'bmi_interp'\n",
    "pima_diabetes <- mutate(pima_diabetes, bmi_interp = ifelse(BMI < 18.5, 'Underweight', \n",
    "                                        ifelse(BMI >= 18.5 & BMI < 25, 'Healthy Weight',\n",
    "                                              ifelse(BMI >= 25 & BMI < 30, 'Overweight',\n",
    "                                                    ifelse(BMI >= 30, 'Obese', NA)))))\n",
    "\n",
    "# Convert from character to categorical\n",
    "pima_diabetes$bmi_interp <- as.factor(pima_diabetes$bmi_interp)\n",
    "\n",
    "cat('\\'bmi_interp\\' variable created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:30.151211Z",
     "start_time": "2020-03-17T01:42:30.061Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head(pima_diabetes[c('BMI', 'bmi_interp')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Limitations and Considerations when using BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI is a simple, inexpensive, and common measure for body fat. However, there are several clinical considerations to keep in mind when using this measure. It's critical to keep in mind BMI is only a surrogate measure since it uses weight instead of actual body fat content in its calculations. Below are three examples of factors that can influence BMI:\n",
    "\n",
    "- age: older adults usually have more body fat than younger adults for the same BMI\n",
    "- gender: women tend to have greater amounts of body fat compared to men for the same BMI\n",
    "- muscle mass: muscular individuals or athletes may have higher BMI due to increased muscle mass\n",
    "\n",
    "[Source](https://www.cdc.gov/obesity/downloads/bmiforpactitioners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *Blood Glucose (mg/dl)*   |\n",
    "| -------------- | ------------------------- |\n",
    "| Diabetic       | 200 ≤ Blood Glucose       |\n",
    "| Prediabetic    | 140 ≤ Blood Glucose < 200 |\n",
    "| Healthy        |  Blood Glucose < 140      |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've cleaned our data we can begin exploring our data. Using this, we can see which features are good candidates for building our prediction model. Feature selection  will determine how good or how bad your model is. Bad feature selection can have a hugely negative impact on your model even if you used the most advanced techniques. Understanding the clinical nuances of your data can inform better feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Why Can't We Just Use All or Most Variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One issue you might be wondering about is why do we even need to select variables. Why not just use all of the variables? After all, more data lead to better models right? This is a common misconception that even experienced analysts need to watch out for. Including too many features in your prediction model can lead to what is known as 'overfitting'. Overfitting is essentially where you build a model that adheres too closely to your current data set and is unable to predict observations that are not from your current data set. In other words, it is where you develop a model that tuned too closely to your current data, and is not generalizable to outside data sources. \n",
    "\n",
    "<img src=\"https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1527613915658.png\" align=\"center\" style=\"width: 50%; margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Getting A Closer Look At Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a closer look as we begin our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:31.752079Z",
     "start_time": "2020-03-17T01:42:31.693Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "str(pima_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:31.828053Z",
     "start_time": "2020-03-17T01:42:31.700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary(pima_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This summary page presents us with quite a bit of data. The first thing to realize is that the output will differ based on whether the variable is numeric or categorical. Numeric outputs will include summary statistics while categorical variables will include frequency counts of each category. \n",
    "\n",
    "These summaries will provide a useful reference throughout our exploratory data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "A chi-square test is a statistical test that tells you whether groups of observations are different. For instance, say you're researching two companies and you divide them either as male or female. The number of males compared to females in the two companies differ but how can you tell that this is not random chance? A chi-squared test can be used to differentiate whether the **observed** number of males and females in your study differs from the **expected** number of males and females. \n",
    "\n",
    "> Note: Chi-square tests can only be used for categorical variables. There are separate tests to determine whether numerical numbers differ form one another. These additional tests are beyond the scope of the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at our other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:32.461477Z",
     "start_time": "2020-03-17T01:42:32.390Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary(pima_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that the most of our predictor variables are numeric with the exception of `bmi_interp`. Let's examine the distribution of these variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:35.127625Z",
     "start_time": "2020-03-17T01:42:32.539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Pregnancies ###\n",
    "# Create Plot\n",
    "pregnancy_plot <- ggplot(pima_diabetes, aes(x=Pregnancies)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=15, color ='black ', fill='light blue') +\n",
    "labs(x='Number of Pregnancies', y='Frequency Count', caption = 'Dashed Line Represents Median Pregnancies (3)')\n",
    "\n",
    "# Display + Median Line\n",
    "pregnancy_plot <- pregnancy_plot + geom_vline(aes(xintercept=median(Pregnancies)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1)\n",
    "\n",
    "### Glucose ###\n",
    "# Create Plot\n",
    "glucose_plot <- ggplot(pima_diabetes, aes(x=Glucose)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Blood Glucose ', y='Frequency Count', caption = 'Dashed Line Represents Median Blood Glucose (117)') \n",
    "\n",
    "# Display + Median Line\n",
    "glucose_plot <- glucose_plot + geom_vline(aes(xintercept=median(Glucose, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### BloodPressure ###\n",
    "# Create Plot\n",
    "bp_plot <- ggplot(pima_diabetes, aes(x=BloodPressure)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Blood Pressure (mm Hg)', y='Frequency Count', caption = 'Dashed Line Represents Median Blood Pressure (72)') \n",
    "\n",
    "# Display + Median Line\n",
    "bp_plot <- bp_plot + geom_vline(aes(xintercept=median(BloodPressure, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### Skin Thickness ###\n",
    "# Create Plot\n",
    "skin_plot <- ggplot(pima_diabetes, aes(x=SkinThickness)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Skin Thickness (mm)', y='Frequency Count', caption = 'Dashed Line Represents Median Skin Thickness (29)') \n",
    "\n",
    "# Display + Median Line\n",
    "skin_plot <- skin_plot + geom_vline(aes(xintercept=median(SkinThickness, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### Diabetes Pedigree ###\n",
    "# Create Plot\n",
    "pedigree_plot <- ggplot(pima_diabetes, aes(x=DiabetesPedigreeFunction)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Diabetes Pedigree Function', y='Frequency Count', caption = 'Dashed Line Represents Median \\nDiabetes Pedigree Function (0.37)') \n",
    "\n",
    "# Display + Median Line\n",
    "pedigree_plot <- pedigree_plot + geom_vline(aes(xintercept=median(DiabetesPedigreeFunction, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### Age ###\n",
    "# Create Plot\n",
    "age_plot <- ggplot(pima_diabetes, aes(x=Age)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Age (years)', y='Frequency Count', caption = 'Dashed Line Represents Median Age (29)') \n",
    "\n",
    "# Display + Median Line\n",
    "age_plot <- age_plot + geom_vline(aes(xintercept=median(Age, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "plot_grid(pregnancy_plot, glucose_plot, bp_plot, skin_plot, pedigree_plot, age_plot, ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There does not appear to be any extreme values or prominent clusters. Now let's see if there is a relationship between diabetes and our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:37.578221Z",
     "start_time": "2020-03-17T01:42:32.912Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Pregnancy ###\n",
    "violin_plot_pregnancy <- ggplot(pima_diabetes, aes(x=Outcome, y=Pregnancies, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Number Pregnancies', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Glucose ###\n",
    "violin_plot_glucose <- ggplot(pima_diabetes, aes(x=Outcome, y=Glucose, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Blood Glucose', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Blood Pressure ###\n",
    "violin_plot_bp <- ggplot(pima_diabetes, aes(x=Outcome, y=BloodPressure, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Blood Pressure (mm Hg)', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Skin Thickness ###\n",
    "violin_plot_skin <- ggplot(pima_diabetes, aes(x=Outcome, y=SkinThickness, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Skin Thickness (mm)', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Diabetes Pedigree function ###\n",
    "violin_plot_pedigree <- ggplot(pima_diabetes, aes(x=Outcome, y=DiabetesPedigreeFunction, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Diabetes Pedigree Function', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Age ###\n",
    "violin_plot_age <- ggplot(pima_diabetes, aes(x=Outcome, y=Age, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Age', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "plot_grid(violin_plot_pregnancy, violin_plot_glucose, violin_plot_bp, violin_plot_skin, \n",
    "          violin_plot_pedigree, violin_plot_age, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Overall, most variables have different distribution between 'No Diabetes' and 'Diabetes'. This indicates that these variables can discriminate between our two outcomes and are likely excellent candidate predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The only exception is `Blood Pressure`. However, we cannot throw out `Blood Pressure`. [Relevant literature](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3314178/) has shown a link between hypertension (high blood pressure) and diabetes. For this reason, we will include `Blood Pressure` in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Balancing Feature Selection with Clinical Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There may be a time where your analysis where your data may show a feature does not have an effect or be a statistically significant feature. These always need to be balanced with clinical knowledge. If you know that something is important clinically that should balance incidental statistical findings. Statistical effects and significance can change based on the characteristics of your data. Always use your clinical/domain knowledge to inform the analytic process when possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now examine our final candidate predictor variable `BMI Interpretaion`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:37.893348Z",
     "start_time": "2020-03-17T01:42:33.846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Plot\n",
    "bmi_plot <- ggplot(data=(subset(pima_diabetes, !is.na(bmi_interp))), aes(x=bmi_interp, fill = Outcome)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='BMI Status', fill = \"Outcome\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "# Display Plot\n",
    "bmi_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that increasing BMI leads to increased proportion of diabetes. We also know this clinically since many of the metabolic risk factors behind obesity/overweight underpin diabetes. All in all this indicates that `BMI Status` is an excellent predictor variable from a data science and clinical perspective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that our variables have been successfully converted and our outcome has been defined, we can analyze our data. Logistic regression is a mathematical model that estimates the probability of a binary outcome (such as our risk label). It is named after the logistic curve which takes the S-shape depicted below.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png?1566122052688\" alt=\"Logistic Curve\" title=\"Logistic Curve\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is our primary outcome? What information will a logistic regression model tell you about our outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Our primary outcome is whether the individual has diabetes. The logistic regression model will allow us to see how individuals variables affect whether an individual has a stroke **while controlling for other variables in the model**. For instance, we can see whether being older affects having diabetes while controlling for weight, genetics, etc...\n",
    "\n",
    "Very useful indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Follow-Up:** What is statistical significance? What is a generally accepted level of statistical significance in healthcare research?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "It will allow us to analyze which variables have a statistically significant effect on whether an asthmatic individual is at high- or low-risk. Logistic regression is a commonly used technique in health analytics because it is easy to interpret and is thought to model the multi-factorial causes of disease well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Statistical Significance can be defined as the chance that the relationship you observed in your data occurred by chance. What does this mean? Let's say our logistic regression model finds that weight has a statistically significant effect on being at high risk or low risk asthmatic patient. This means that it is more likely that there is indeed a relationship between weight and risk than chance would suggest. \n",
    "\n",
    "The conventional level of significance that is accepted is < 0.05 (this number is referred to as a p-value). This means that there is less than 5% chance that the observed relationship in the data was due to chance alone. The image below displays a sample R output.\n",
    "\n",
    "<img src=\"https://drchrispook.files.wordpress.com/2017/02/anova-output-from-r1.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's create out logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:37.941367Z",
     "start_time": "2020-03-17T01:42:35.078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating a logistic regression model\n",
    "mylogit <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + \n",
    "               bmi_interp +Insulin+ DiabetesPedigreeFunction + Age,\n",
    "               data = pima_diabetes, family = \"binomial\")\n",
    "mylogit.sum <- summary(mylogit)\n",
    "mylogit.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that several of our variables do not have a statistically significant effect. Several of these variables are clinically relevant. For instance, we know that hypertensive and older individuals are at higher risk for diabetes. For this reason we will be keeping it in our model. \n",
    "\n",
    "While statistical significance is important, it is always more important to consider whether our predictors are clinically relevant for the outcome we will be predicting. Remember to alway consider the clinical significance of a variable and not just the statistical significance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building A Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** So far we haven't done any machine learning yet. What we've done can be considered traditional statistical analysis. What differentiate machine learning for statistical analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "In machine learning, data is split into a training set and a test set. A machine learning model is then trained on the training set to predict whatever outcome of interest it was designed to predict (in our case we're predicting whether the patient has diabetes). The model's predictive performance is then evaluated using the test set. \n",
    "\n",
    "<img src=\"https://www.sqlservercentral.com/wp-content/uploads/2019/05/Image-2.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For our case, we will be using a model called gradient boosting machines. To understand gradient boosting machines we first must understand what boosting and decision trees are. Boosting is the process of converting a weak learner into a strong learner. Decision trees are charts which help make a decision or prediction. Each branch represents a possible outcome. The end of branches represent an end result or decision.\n",
    "\n",
    "Decision trees are common in medical settings. For instance, below is an algorithm for evaluating febrile seizures. This is an example of a decision tree.\n",
    "\n",
    "<img src=\"https://img.grepmed.com/uploads/1105/febrileseizure-management-algorithm-diagnosis-complex-original.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In gradient boosting machines, train numerous decision trees. With each training iteration, the algorithm identifies weak decision trees, and subsequently improves on this tree. This process continues until we have our final model. This final model is a curated and weighted sum of the predictions made by previous decision trees run by the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now need to split our data into training and test data. We will be splitting our data into 80% training data and 20% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:39.859783Z",
     "start_time": "2020-03-17T01:42:35.876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and test set data\n",
    "# Setting the seed value so we get the same result when we repreat\n",
    "set.seed(100)\n",
    "\n",
    "# Imputing Na w/ mice package so that our model works\n",
    "pima_diabetes <- pima_diabetes %>%\n",
    "    mutate(\n",
    "        Glucose = as.numeric(Glucose),\n",
    "        BloodPressure = as.numeric(BloodPressure),\n",
    "        SkinThickness = as.numeric(SkinThickness)\n",
    "    )\n",
    "\n",
    "suppressWarnings(mice_impute <- mice(pima_diabetes, m=1, maxit=10))\n",
    "pima_diabetes <- complete(mice_impute, 1)\n",
    "\n",
    "# Determining which rows willbe in the traiing data\n",
    "training_index <- sample(nrow(pima_diabetes), 0.8*nrow(pima_diabetes), replace = FALSE)  \n",
    "\n",
    "# Create Training Set\n",
    "training_data <- pima_diabetes[training_index,]\n",
    "\n",
    "# Create Test Set\n",
    "test_data <- pima_diabetes[-training_index,]\n",
    "\n",
    "cat('Training and Test Data Created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T03:55:52.200081Z",
     "start_time": "2019-10-24T03:55:52.180Z"
    },
    "hidden": true
   },
   "source": [
    "Now let's fit our model to the training data. We will then take a look at our model's performance using the test data and a confusion matrix.\n",
    "\n",
    "> If you're unsure what a confusion matrix is, please consult section 5.0.1 ('What is a Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:44.961207Z",
     "start_time": "2020-03-17T01:42:35.961Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "model <- (Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + bmi_interp +Insulin+ DiabetesPedigreeFunction + Age)\n",
    "\n",
    "# Add in NA action to exclude missing \n",
    "model_gbm <- suppressWarnings(train(model, data=training_data, method=\"gbm\", na.action = na.omit,verbose=FALSE))\n",
    "\n",
    "# Predict\n",
    "prediction_gbm <- predict(model_gbm, test_data[,-9])\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix(prediction_gbm, test_data$Outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we can see several useful metrics for our model. For instance, we have an `Accuracy` of 0.83, a `Sensitivity` of 0.63 anda `Specificity` of 0.91. The necessary metrics will depend on the task a model is designed for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What Is A Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A confusion matrix is a 2x2 table which computes 4 different combinations of predicted vs. actual values. The combinations are True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/320/1*Z54JgbS4DUwWSknhDCvNTQ.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    "These 4 interpretations can be combined to generate many useful metrics. For our purpose there are three we will focus on. The first is accuracy:\n",
    "\n",
    "\\[\\large (TP + TN)/Total\\]\n",
    "\n",
    "Accuracy allows us to measure how often our model predicted correctly. The second metric is sensitivity:\n",
    "\n",
    "\\[\\large TP / (TP + FN)\\]\n",
    "\n",
    "Sensitivity asks the question, that when our outcome is actually positive (ie. in our case when our patient actually has diabetes) how often will the model predict positively (ie. how often will the model then predict the patient to have diabetes). The final metric is specificity:\n",
    "\n",
    "\\[\\large TN / (FP + TN)\\]\n",
    "\n",
    "Specificity asks the question, that when the outcome is actually negative (ie. in our case when our patient actually has diabetes) how often will the model predict negatively (ie. how often will the model then predict the patient to have diabetes). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will be evaluating our model using a receiver operating curve (ROC) and the area under the curve (AUC) value. \n",
    "\n",
    "> If you're unsure what a ROC or AUC value is, please consult section 5.1.1 ('Understanding ROC Curves and AUC Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.197965Z",
     "start_time": "2020-03-17T01:42:36.398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a ROC curve\n",
    "ROC <- roc(response = test_data$Outcome, predictor = factor(prediction_gbm, \n",
    "                                                           ordered = TRUE))\n",
    "\n",
    "# Plot ROC with ggplot2\n",
    "plot_ROC <- ggroc(ROC)\n",
    "plot_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.222974Z",
     "start_time": "2020-03-17T01:42:36.405Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat('AUC:', round(auc(ROC), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The closer to the top left corner our ROC curve, the better. The higher our AUC value, the better. These metrics provide useful measures when tuning our model. They are also better overall measures than accuracy alone. We can compare different models using these two metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Understanding ROC Curves and AUC Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A ROC plots sensitivity (probability of predicting a real positive will be positive) against 1-specificity (the probability of predicting a real negative will be positive). A model with a 50-50 chance of making a correct decision will have a ROC curve which is just a diagonal line. A model with a curve that hugs the top left corner is a perfect model. The area under a curve is a measure of the magnitude of the ROC curve. The closer the ROC curve is to the top left corner, the higher the AUC value. The higher the AUC value, the better. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/406/1*pk05QGzoWhCgRiiFbz-oKQ.png\" style=\"float: center; width: 34%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Explaining our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important part of understanding and communicating the results of any model is explaining the model. We can dive further into our model by assessing which variables were most important for our model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.472595Z",
     "start_time": "2020-03-17T01:42:36.854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test <- varImp(model_gbm)\n",
    "ggplot(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that `Glucose` was by far the most important variable. This makes sense since diabetes is a reflection of abnormally high blood glucose levels. What's surprising is how much of an effect that `DiabetsPedigreeFunction` is. There are two variants of diabetes, Type 1 and Type 2. Type 2 diabetes has a strong genetic component. This indicates many in our data have type 2 diabetes. Variable importance can be a good way to look for surprising results. Any surprising variables can be the subject of further investigation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You've now learned everything you need to begin testing your own models! Analytics is an iterative process and requires constantly tuning and testing different models against one another. One of the most important ways to tune your models is to decide what features/variables to include on your model. This will have a huge impact on your models performance. Run the code below to see all the features in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.505206Z",
     "start_time": "2020-03-17T01:42:37.222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:39:03.380360Z",
     "start_time": "2020-03-17T01:39:03.343Z"
    },
    "hidden": true
   },
   "source": [
    "From the list of features above, pick the features you believe are the most predictive for predicting diabetes. You can type in your features in between the brackets below. Please follow the format shown in the example below.\n",
    "\n",
    "<code>c(\"Pregnancies\",\"BloodPressure\")</code>\n",
    "\n",
    "Be careful! If there are any typo, this will not work and you will need to run the code below again with the typo corrected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.530177Z",
     "start_time": "2020-03-17T01:42:37.336Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features <- c(\"Pregnancies\",\"Glucose\",\"BloodPressure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we will see how our model performs using the features you selected. The below code will output evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:43:36.565022Z",
     "start_time": "2020-03-17T01:43:32.043Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Experiment with different features. As mentioned earlier, feature selection makes a huge difference in model performance. Determine which features work best and see if you can beat the model we built earlier in the case! You can rerun the <code>test_model()</code> function with new features as many times as you like. Please refer to the instructions after our variable list to see how to select new features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Congratulations! You've reached the end of the case! This case provided just one example of how analytics and healthcare can be combined to solve clinical problems. I hope your curiosity has been piqued. There will be much more to learn and much more you can explore in this field!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "414px",
    "left": "54px",
    "top": "110.8px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
