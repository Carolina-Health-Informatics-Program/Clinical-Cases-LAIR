{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "<p align=\"justify\">Welcome! In this case we'll be exploring how to use advanced analytic and machine learning techniques to predict diabetes among the Pima Indian population. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Some of the skills you'll explore are (Click to Expand):</summary>\n",
    "<ul>\n",
    "    <li>R Programming</li>\n",
    "    <li>Data Cleaning</li>\n",
    "    <li>Exploratory Data Analysis</li>\n",
    "    <li>Data Visualization</li>\n",
    "    <li>Leveraging Domain Knowledge</li>\n",
    "    <li>Machine Learning</li>\n",
    "    <li>Gradient Boosting Machines</li>\n",
    "</details><br>\n",
    "Don't worry if you're unsure what some of these terms are. They'll be explained throughout the case. Let's begin! \n",
    "<img src=\"https://i.stack.imgur.com/zlAi2.png\" style=\"float: left; width: 33%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://cdn.images.express.co.uk/img/dynamic/11/590x/Diabetes-symptoms-870995.jpg\" style=\"float: left; width: 35%; margin-bottom: 0.5em;\">\n",
    "<img src=\"https://46gyn61z4i0t1u1pnq2bbk2e-wpengine.netdna-ssl.com/wp-content/uploads/2018/11/sankey-diagram-1.png\" style=\"float: left; width: 28%; margin-left: 1%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "## Case Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine you're a statistical officer for the Indian Health Service (IHS). Your state has recently obtained a federal grant aimed at improving health equity. This includes improving care among traditionally disadvantaged groups. From working within the IHS for several years now, you know that American Indians are more likely to suffer from metabolic diseases, particularly diabetes. \n",
    "\n",
    "<img width=\"400\" height=325 src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Indian_Health_Service_Logo.svg/1200px-Indian_Health_Service_Logo.svg.png\">\n",
    "\n",
    "With this grant, you now have the chance to leverage new technologies in analytics and machine learning to improve care among this group. If you can predict diabetes in patients before it manifests symptomatically, you can preemptively target preventative services toward this population. However, you have to first develop a way to predict diabetes. How can you do this?\n",
    "\n",
    "Continue the case to find out how"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra: What is Diabetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Diabetes describes a group of metabolic disorders that is characterized by abnormally high blood glucose (blood sugar). Insulin is a critical hormone that allows the body to take up glucose and use it as energy. Diabetes occurs when your body does not produce enough insulin or cannot use insulin well. When this happens, glucose stays in your blood instead of being used as energy. Over time, this glucose in your blood can lead to various health problems. These can include serious complications such as blindness, limb amputation, and stroke. \n",
    "\n",
    "<img src=\"http://cdn.shopify.com/s/files/1/0582/0445/files/blood-sugar-levels-and-paleo_diagram_of_excessive_blood_glucose.jpg?14686865159083212781\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    "Diabetes is common among individuals over 45 years old, have a family history of diabetes, and are overweight. Poor lifestyle choices such as not exercising or smoking can also increase the risk. Diabetes is one of the most common conditions in the United States with over 30 million people suffering from diabetes. The total estimated cost of diabetes to the health care system is estimated to be $327 Billion. Current treatment includes insulin and medication to control blood glucose levels. Lifestyle modifications before the onset of diabetes can make a huge difference in whether a person develops diabetes. Any algorithm which could reliably predict diabetes could give providers critical information to intervene before a patient has diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## How To Run The Case (Do Not Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we begin the case, we need to know how to use Jupyter Notebook and run the case. First, look for the the `Run` button. The location of the `Run` button is shown below and can be found in the tool bar above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "\n",
    "<img src=\"https://i.imgur.com/jr4dpLW.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The cell below is a code cell. You will be running numerous code cells like the one below throughout the case. Select the cell and select the run button above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:29.718399Z",
     "start_time": "2020-03-17T21:47:29.630Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is an example of a code cell\n",
    "cat('Congratulations! \\n')\n",
    "cat('You\\'ve run your first code cell.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width = 50 height = 50 style=\"float: left; margin-right: 10px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/Stop_sign_dark_red.svg\">Stop! If you have not learned to run a code cell, restart this section. You will not be able to go through the case at all if you are unable to run code cells. Otherwise, it's time to meet our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Meeting Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll be using a set of patient data made available by the National Institute of Diabetes and Digestive and Kidney Diseases. It's important to note that several constraints were made in order to acquire the dataset. All patients are female, at least 21 years old, and of Pima Indian heritage. The variables selected were chosen due to being significant risk factors for diabetes among Pimas or other population groups. The data is hosted on the [University of California Irvine's Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/diabetes). \n",
    "\n",
    "**Acknowledgements** <br>\n",
    "Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data First Look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets get a first glimpse of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:29.798387Z",
     "start_time": "2020-03-17T21:47:29.639Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pima_diabetes <- read.csv(file=\"data/diabetes.csv\",  encoding=\"UTF-8\", header=TRUE, sep=\",\")\n",
    "head(pima_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What do you notice? Do you notice anything unusual about the data? Don't worry if you don't notice anything. We will be getting to know our data better as we go through the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data Variable Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are several variables or labels which you might not understand. The way to combat this is by consulting the data dictionary. \n",
    "\n",
    "> A data dictionary describes a dataset and provides information on the meaning of each variable. Always look for documentation or a data dictionary before starting an analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unfortunately, no documentation is provided on the original data page. However, the original study the data comes from is available [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/pdf/procascamc00018-0276.pdf). The relevant information has been added below for your convenience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Variable*               | *Definition*                                                         |\n",
    "| ------------------------ | -------------------------------------------------------------------- |\n",
    "| Pregnancies              | Number of times pregnant                                             |\n",
    "| Glucose                  | Plasma glucose concentration following a 2 hour oral glucose tolerance test                                             |\n",
    "| BloodPressure            | Diastolic Blood Pressure (mm Hg)                                     | \n",
    "| SkinThickness            | Triceps Skin Fold Thickness (mm)                                     |\n",
    "| Insulin                  | 2-Hour Serum Insulin Levels                                          |\n",
    "| BMI                      | Weight in kg / (Heigh in m)^2                                        |\n",
    "| DiabetesPedigreeFunction | Measure of expected genetic influence on the subject's diabetes risk |\n",
    "| Age                      | Age (Years)                                                          |\n",
    "| Outcome                  | Diabetes as defined as plasma glucose concentration > 200 mg/dl two hours after ingestion of 75 gram carbohydrate solution |\n",
    "\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup (Do Not Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below will set up specific settings for the case to run properly. Do not worry if you do not understand what the code is doing, this will not impact your understanding of the case. Run the code below to complete the setup for the case. Do not skip this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.036419Z",
     "start_time": "2020-03-17T21:47:29.646Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Increase max number of columns displayed in output tables\n",
    "options(repr.matrix.max.cols = 50)\n",
    "set.seed(10) # Make sure your ML results are the same\n",
    "\n",
    "# Calling external libraries for additional functionality\n",
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(randomForest))\n",
    "suppressMessages(library(forcats))\n",
    "suppressMessages(library(cowplot))\n",
    "suppressMessages(library(caret))\n",
    "suppressMessages(library(e1071))\n",
    "suppressMessages(library(pROC))\n",
    "suppressMessages(library(mice))\n",
    "suppressMessages(library(gbm))\n",
    "\n",
    "# Create function to test models\n",
    "test_model <- function(features){\n",
    "    # Set up the model\n",
    "    total_variables <- append(features,\"Outcome\")\n",
    "    play_trainingData <- subset(training_data,select = total_variables)\n",
    "    play_testData <- subset(test_data,select = total_variables)\n",
    "    # Add in NA action to exclude missing \n",
    "    model_gbm <- train(Outcome~., data=play_trainingData, method=\"gbm\", na.action = na.omit,verbose=FALSE)\n",
    "\n",
    "    # Predict\n",
    "    prediction_gbm <- predict(model_gbm, play_testData)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm <- confusionMatrix(prediction_gbm, play_testData$Outcome)\n",
    "    print(cm)\n",
    "    # Create a ROC curve\n",
    "    ROC <- roc(response = play_testData$Outcome, predictor = factor(prediction_gbm, \n",
    "                                                               ordered = TRUE))\n",
    "\n",
    "    # Plot ROC with ggplot2\n",
    "    plot_ROC <- ggroc(ROC)\n",
    "    print(plot_ROC)\n",
    "    cat('AUC:', round(auc(ROC), 2),'\\n')\n",
    "    test <- varImp(model_gbm)\n",
    "    ggplot(test)\n",
    "    }\n",
    "\n",
    "cat('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "><img width = 50 height = 50 style=\"float: left; margin-right: 10px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/Stop_sign_dark_red.svg\">Stop! If you have not run the code cell above, please do so. The case will not work properly if you do not complete the setup. Otherwise, lets begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cleaning Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first step in any analytic project is to clean our data. This is a critical step which will ensure our data is correct, consistent, and ready for analysis. If we do not properly process our data, we will not able to analyze it effectively regardless of how advanced our analytic technique is. A common saying in data analysis is \"Junk in, Junk out\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inspecting Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll begin by reading in our data. This means we will be loading the data onto the system so Python can understand the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.178980Z",
     "start_time": "2020-03-17T21:47:29.651Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note: Unicode Transformation Format – 8 (UTF-8) is a standard to encode characters in different languages\n",
    "cat('Data loading, please wait\\n')\n",
    "pima_diabetes <- read.csv(file=\"data/diabetes.csv\",  encoding=\"UTF-8\", header=TRUE, sep=\",\")\n",
    "cat('Data loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's get an overview of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.224406Z",
     "start_time": "2020-03-17T21:47:29.655Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head(pima_diabetes)\n",
    "str(pima_diabetes)\n",
    "summary(pima_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the most part all values are classified correctly as numeric or categorical besides the `Outcome` variable.  In addition there seem to be some odd values. There are individuals with a `BMI` of 0 or 67.1, likely implausible values. Other instances of implausible values include a `Glucose` of 0, 17 `Pregnancies`, and `SkinThickness` of 99 mm. We will consider all of these characteristics as we clean our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Recoding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sometime, the data you receive may be coded in such a way that is not easily understandable. Recoding the data (turning the data into a more easily human readable format) can help make your analysis quicker and smoother. \n",
    "\n",
    "The only variable we need to recode for our data is `Outcome`. Lets recode the variable `Outcome` into something meaningful. Based upon the data dictionary, we can see that `1` indicates the patient is classified as having Diabetes. `0` indicates they are not classified as having diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.250378Z",
     "start_time": "2020-03-17T21:47:29.660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Recoding\n",
    "pima_diabetes$Outcome <- ifelse(pima_diabetes$Outcome == 1, 'Diabetes', \n",
    "                               ifelse(pima_diabetes$Outcome == 0, 'No diabetes', NA))\n",
    "\n",
    "# Convert from character to factor\n",
    "pima_diabetes$Outcome <- as.factor(pima_diabetes$Outcome)\n",
    "cat('Data Recoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.276467Z",
     "start_time": "2020-03-17T21:47:29.664Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(pima_diabetes[c('Outcome')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we will check for missing values. Missing values may unknowingly influence our results. For instance, if the missing data differs from the non-missing data in a significant way, this could lead you to draw erroneous conclusions from incomplete data. \n",
    "\n",
    "Let's examine the number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.304392Z",
     "start_time": "2020-03-17T21:47:29.669Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat('Number of Missing Data for Each Variable:')\n",
    "sapply(pima_diabetes, function(x) sum(is.na(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is very interesting. There are no missing values. If this is true, then this is an incredibly clean dataset. However, this is rarely the case. It's more likely that R cannot recognize the missing or erroneous values as being missing. \n",
    "\n",
    "All of our variables are numeric so it is unlikely there will be categories of erroneously coded data. The more likely option is that there are implausible values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Removing Implausible Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is important to check you data for an implausible value. These data can influence your final analysis in undesirable ways. Often, these data are the result of mistakes rather than actual outliers and can lead to erroneous conclusions\n",
    "\n",
    "Earlier we saw several possible implausible values. These include `Glucose`, `BloodPressure`, `SkinThickness`, `Pregnancies`, `Insulin`, and `BMI`. Lets take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.368689Z",
     "start_time": "2020-03-17T21:47:29.674Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat('Glucose:')\n",
    "quantile(pima_diabetes$Glucose, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Blood Pressure:')\n",
    "quantile(pima_diabetes$BloodPressure, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Skin Thickness:')\n",
    "quantile(pima_diabetes$SkinThickness, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Serum Insulin:')\n",
    "quantile(pima_diabetes$Insulin, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('BMI:')\n",
    "quantile(pima_diabetes$BMI, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))\n",
    "cat('Pregnancies')\n",
    "quantile(pima_diabetes$Pregnancies, c(0, .01, .05, .10, .25, .50, .75, .90, .95, .99, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on the percentiles above, we can get a better sense of implausible and plausible values. Based on the results we can make the following judgements:\n",
    "\n",
    "**Glucose:**\n",
    "- Glucose is unlikely to go below 50 with the 1st percentile being 57. The 0 glucose measurement is physiologically impossible and likely to be an error or missing\n",
    "\n",
    "**Blood Pressure:**\n",
    "- Diastolic blood pressure is unlikely to go below 30 with the 5th percentile being 38.7. Patients at this level are likely to be considered hypotensive or in shock. 0 diastolic blood pressure is physiologically impossible and likely to be an error or missing.\n",
    "\n",
    "**Skin Thickness:**\n",
    "-  It is biologically unlikely that skin thickness would be above 80 mm or below 10 mm. This is confirmed by our percentile data with a huge jump between the 99th and 100th percentile. \n",
    "\n",
    "**Serum Insulin:**\n",
    "-  2 hour serum insulin levels are physiologically unlikely to fall below 10 or above 300. This is confirmed by our percentile results. The jump from 95th to 99th and 100th percentile is enormous. In addition the values 0 for serum insulin are physiologically impossible and likely errors. \n",
    "\n",
    "**BMI:**\n",
    "- BMI is unlikely to go above the 99th percentile of 50.759. The maximum of 67.1 seems biologically implausible. \n",
    "- BMI below the 5th percentile of 21.8 are possible. However, BMI values of 0 are likely mistakes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on these findings, let's reclassify implausible values as `Na`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.397950Z",
     "start_time": "2020-03-17T21:47:29.678Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pima_diabetes$Glucose[pima_diabetes$Glucose < 50] <- NA\n",
    "pima_diabetes$BloodPressure[pima_diabetes$BloodPressure < 30] <- NA\n",
    "pima_diabetes$SkinThickness[pima_diabetes$SkinThickness < 10 | pima_diabetes$SkinThickness > 80] <- NA\n",
    "pima_diabetes$Insulin[pima_diabetes$Insulin < 10 | pima_diabetes$Insulin > 500] <- NA\n",
    "pima_diabetes$BMI[pima_diabetes$BMI < 10 | pima_diabetes$BMI > 50] <- NA\n",
    "\n",
    "cat('Data Recoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "While our data is not as clean, this is a more realistic result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Creating Clinically Relevant Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our data includes the raw lab values for BMI. This is not a very useful measure by itself. Let's convert it into something more clinically meaningful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI stands for Body Mass Index. This is a measure of body weight based upon a person's weight and height. This measure is commonly used to classify individuals as being overweight or a healthy weight. Below is the formula for BMI. \n",
    "\n",
    "\\begin{equation*}\n",
    "\\large BMI = \\frac{\\large weight (kg)}{\\large height (m^2)}\n",
    "\\end{equation*}\n",
    "\n",
    "We will create a new variable which reflects the clinical cutoffs for bmi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Knowledge Check:** What are the clinical cut-offs for BMI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "<center>\n",
    "\n",
    "| *Category*     | *BMI Range*     |\n",
    "| -------------- | --------------- |\n",
    "| Underweight    | BMI < 18.5      |\n",
    "| Healthy Weight | 18.5 ≤ BMI < 25 |\n",
    "| Overweight     | 25 ≤ BMI < 30   |\n",
    "| Obese          | 30 ≥ BMI        |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let create the new variable `bmi_interp` based on these cut-offs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.441568Z",
     "start_time": "2020-03-17T21:47:29.685Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create 'bmi_interp'\n",
    "pima_diabetes <- mutate(pima_diabetes, bmi_interp = ifelse(BMI < 18.5, 'Underweight', \n",
    "                                        ifelse(BMI >= 18.5 & BMI < 25, 'Healthy Weight',\n",
    "                                              ifelse(BMI >= 25 & BMI < 30, 'Overweight',\n",
    "                                                    ifelse(BMI >= 30, 'Obese', NA)))))\n",
    "\n",
    "# Convert from character to categorical\n",
    "pima_diabetes$bmi_interp <- as.factor(pima_diabetes$bmi_interp)\n",
    "\n",
    "cat('\\'bmi_interp\\' variable created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's confirm our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:47:33.468533Z",
     "start_time": "2020-03-17T21:47:29.688Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head(pima_diabetes[c('BMI', 'bmi_interp')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Limitations and Considerations when using BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BMI is a simple, inexpensive, and common measure for body fat. However, there are several clinical considerations to keep in mind when using this measure. It's critical to keep in mind BMI is only a surrogate measure since it uses weight instead of actual body fat content in its calculations. Below are three examples of factors that can influence BMI:\n",
    "\n",
    "- age: older adults usually have more body fat than younger adults for the same BMI\n",
    "- gender: women tend to have greater amounts of body fat compared to men for the same BMI\n",
    "- muscle mass: muscular individuals or athletes may have higher BMI due to increased muscle mass\n",
    "\n",
    "[Source](https://www.cdc.gov/obesity/downloads/bmiforpactitioners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've cleaned our data we can begin exploring our data and selecting variables (also known as features) which we predict will be good candidates for our predictive model. How will we know which features are good candidates? One way we can quantitatively assess our variables is through descriptive analysis and data visualization. We will explore our data based on their data type (quantitative or categorical). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "What are quantitative and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "- **Quantitative:** variables whose values are whole numbers (ie. numbers, percents)\n",
    "- **Categorical:** variables whose values are selected from a group (ie. dog breeds, male/female) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Why Can't We Just Use All or Most Variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One issue you might be wondering about is why do we even need to select variables. Why not just use all of the variables? After all, more data lead to better models right? This is a common misconception that even experienced analysts need to watch out for. Including too many features in your prediction model can lead to what is known as 'overfitting'. Overfitting is essentially where you build a model that adheres too closely to your current data set and is unable to predict observations that are not from your current data set. In other words, it is where you develop a model that tuned too closely to your current data, and is not generalizable to outside data sources. \n",
    "\n",
    "<img src=\"https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1527613915658.png\" align=\"center\" style=\"width: 50%; margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First we will examine the quantitative or numeric variables. The code below will give us an overview of the structure of our data. Look for variables with the label `int` or `num`. These are two kinds of quantitative variables in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:32.461477Z",
     "start_time": "2020-03-17T01:42:32.390Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "str(pima_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that the most of our predictor variables are numeric with the exception of `bmi_interp`. Let's examine the distribution of the quantitative variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:52:22.476390Z",
     "start_time": "2020-03-17T21:52:21.252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Pregnancies ###\n",
    "# Create Plot\n",
    "pregnancy_plot <- ggplot(pima_diabetes, aes(x=Pregnancies)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=15, color ='black ', fill='light blue') +\n",
    "labs(x='Number of Pregnancies', y='Frequency Count', caption = 'Dashed Line Represents Median Pregnancies (3)')\n",
    "\n",
    "# Display + Median Line\n",
    "pregnancy_plot <- pregnancy_plot + geom_vline(aes(xintercept=median(Pregnancies)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1)\n",
    "\n",
    "### Glucose ###\n",
    "# Create Plot\n",
    "glucose_plot <- ggplot(pima_diabetes, aes(x=Glucose)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Blood Glucose ', y='Frequency Count', caption = 'Dashed Line Represents Median Blood Glucose (117)') \n",
    "\n",
    "# Display + Median Line\n",
    "glucose_plot <- glucose_plot + geom_vline(aes(xintercept=median(Glucose, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### BloodPressure ###\n",
    "# Create Plot\n",
    "bp_plot <- ggplot(pima_diabetes, aes(x=BloodPressure)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Blood Pressure (mm Hg)', y='Frequency Count', caption = 'Dashed Line Represents Median Blood Pressure (72)') \n",
    "\n",
    "# Display + Median Line\n",
    "bp_plot <- bp_plot + geom_vline(aes(xintercept=median(BloodPressure, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### Skin Thickness ###\n",
    "# Create Plot\n",
    "skin_plot <- ggplot(pima_diabetes, aes(x=SkinThickness)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Skin Thickness (mm)', y='Frequency Count', caption = 'Dashed Line Represents Median Skin Thickness (29)') \n",
    "\n",
    "# Display + Median Line\n",
    "skin_plot <- skin_plot + geom_vline(aes(xintercept=median(SkinThickness, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### Diabetes Pedigree ###\n",
    "# Create Plot\n",
    "pedigree_plot <- ggplot(pima_diabetes, aes(x=DiabetesPedigreeFunction)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Diabetes Pedigree Function', y='Frequency Count', caption = 'Dashed Line Represents Median \\nDiabetes Pedigree Function (0.37)') \n",
    "\n",
    "# Display + Median Line\n",
    "pedigree_plot <- pedigree_plot + geom_vline(aes(xintercept=median(DiabetesPedigreeFunction, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "### Age ###\n",
    "# Create Plot\n",
    "age_plot <- ggplot(pima_diabetes, aes(x=Age)) +\n",
    "geom_histogram(alpha = 0.5, position = 'identity', bins=20, color ='black ', fill='light blue') +\n",
    "labs(x='Age (years)', y='Frequency Count', caption = 'Dashed Line Represents Median Age (29)') \n",
    "\n",
    "# Display + Median Line\n",
    "age_plot <- age_plot + geom_vline(aes(xintercept=median(Age, na.rm=TRUE)),\n",
    "            color=\"blue\", linetype=\"dashed\", size=1) \n",
    "\n",
    "plot_grid(pregnancy_plot, glucose_plot, bp_plot, skin_plot, pedigree_plot, age_plot, ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There does not appear to be any extreme values or prominent clusters. Now let's see if there is a relationship between diabetes and our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:52:29.420366Z",
     "start_time": "2020-03-17T21:52:27.984Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Pregnancy ###\n",
    "violin_plot_pregnancy <- ggplot(pima_diabetes, aes(x=Outcome, y=Pregnancies, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Number Pregnancies', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Glucose ###\n",
    "violin_plot_glucose <- ggplot(pima_diabetes, aes(x=Outcome, y=Glucose, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Blood Glucose', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Blood Pressure ###\n",
    "violin_plot_bp <- ggplot(pima_diabetes, aes(x=Outcome, y=BloodPressure, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Blood Pressure (mm Hg)', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Skin Thickness ###\n",
    "violin_plot_skin <- ggplot(pima_diabetes, aes(x=Outcome, y=SkinThickness, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Skin Thickness (mm)', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Diabetes Pedigree function ###\n",
    "violin_plot_pedigree <- ggplot(pima_diabetes, aes(x=Outcome, y=DiabetesPedigreeFunction, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Diabetes Pedigree Function', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "### Age ###\n",
    "violin_plot_age <- ggplot(pima_diabetes, aes(x=Outcome, y=Age, color = Outcome, fill = Outcome)) + \n",
    "geom_violin(alpha = 0.3, trim = FALSE) + # By default tails are trimmed\n",
    "stat_summary(fun.y=median, geom=\"point\", shape = 23, size = 2) +\n",
    "theme(legend.position='none') +\n",
    "labs(y='Age', x='Diabetes Status') +\n",
    "coord_flip()\n",
    "\n",
    "plot_grid(violin_plot_pregnancy, violin_plot_glucose, violin_plot_bp, violin_plot_skin, \n",
    "          violin_plot_pedigree, violin_plot_age, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Overall, most variables have different distribution between 'No Diabetes' and 'Diabetes'. This indicates that these variables can discriminate between our two outcomes and are likely excellent candidate predictor variables. However, there is one variable which does not appear to have a very different distribution? Which variable is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "The only exception is `Blood Pressure`. However, we cannot completely discount `Blood Pressure`. [Relevant literature](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3314178/) has shown a link between hypertension (high blood pressure) and diabetes. For this reason, `Blood Pressure` still could be a feature in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Balancing Feature Selection with Domain Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There may be a time where your analysis where your data may show a feature does not have an effect or be a statistically significant feature. These always need to be balanced with clinical knowledge. If you know that something is important clinically that should balance incidental statistical findings. Statistical effects and significance can change based on the characteristics of your data. Always use your clinical/domain knowledge to inform the analytic process when possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Assessing Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now examine our final candidate predictor variable `BMI Interpretaion`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:37.893348Z",
     "start_time": "2020-03-17T01:42:33.846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Plot\n",
    "bmi_plot <- ggplot(data=(subset(pima_diabetes, !is.na(bmi_interp))), aes(x=bmi_interp, fill = Outcome)) + \n",
    "geom_bar(position='fill') +\n",
    "labs(y='Proportion', x='BMI Status', fill = \"Outcome\") +\n",
    "theme(legend.position = 'none') + theme(axis.title.y=element_blank())\n",
    "\n",
    "# Display Plot\n",
    "bmi_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that increasing BMI leads to increased proportion of diabetes. We also know this clinically since many of the metabolic risk factors behind obesity/overweight underpin diabetes. All in all this indicates that `BMI Status` is an excellent predictor variable from a data science and clinical perspective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that our variables have been successfully converted and our outcome has been defined, we can analyze our data. Logistic regression is a mathematical model that estimates the probability of a binary outcome (such as our risk label). It is named after the logistic curve which takes the S-shape depicted below.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png?1566122052688\" alt=\"Logistic Curve\" title=\"Logistic Curve\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** What is our primary outcome? What information will a logistic regression model tell you about our outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Our primary outcome is whether the individual has diabetes. The logistic regression model will allow us to see how individuals variables affect whether an individual has a stroke **while controlling for other variables in the model**. For instance, we can see whether being older affects having diabetes while controlling for weight, genetics, etc...\n",
    "\n",
    "Very useful indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Follow-Up:** What is statistical significance? What is a generally accepted level of statistical significance in healthcare research?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "It will allow us to analyze which variables have a statistically significant effect on whether an asthmatic individual is at high- or low-risk. Logistic regression is a commonly used technique in health analytics because it is easy to interpret and is thought to model the multi-factorial causes of disease well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "Statistical Significance can be defined as the chance that the relationship you observed in your data occurred by chance. What does this mean? Let's say our logistic regression model finds that weight has a statistically significant effect on being at high risk or low risk asthmatic patient. This means that it is more likely that there is indeed a relationship between weight and risk than chance would suggest. \n",
    "\n",
    "The conventional level of significance that is accepted is < 0.05 (this number is referred to as a p-value). This means that there is less than 5% chance that the observed relationship in the data was due to chance alone. The image below displays a sample R output.\n",
    "\n",
    "<img src=\"https://drchrispook.files.wordpress.com/2017/02/anova-output-from-r1.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's create out logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:57:48.204687Z",
     "start_time": "2020-03-17T21:57:48.130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating a logistic regression model\n",
    "mylogit <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + \n",
    "               bmi_interp +Insulin+ DiabetesPedigreeFunction + Age,\n",
    "               data = pima_diabetes, family = \"binomial\")\n",
    "mylogit.sum <- summary(mylogit)\n",
    "mylogit.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above model allows us to see what variables are considered to have a statically significant effect on risk for diabetes. For instance, `Glucose` has a statistically significant effect with a p-value of 2.07e-10. \n",
    "\n",
    "Keep in mind that even if a variable is not statistically significant does not mean it is a poor feature. If you have domain knowledge which indicate a feature is particularly important for your outcome, you should still consider including that feature in your model. Clinical significance is more important than statistical significance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Building A Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are now ready to build a predictive model. If all goes well, we will have a tool that will accurately predict which patients will develop diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pre-Check:** So far we haven't done any machine learning yet. What we've done can be considered traditional statistical analysis. What differentiate machine learning for statistical analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "source": [
    "In machine learning, data is split into a training set and a test set. A machine learning model is then trained on the training set to predict whatever outcome of interest it was designed to predict (in our case we're predicting whether the patient has diabetes). The model's predictive performance is then evaluated using the test set. \n",
    "\n",
    "<img src=\"https://www.sqlservercentral.com/wp-content/uploads/2019/05/Image-2.jpg\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important decision you have to make when building your model is to decide what kind of predictive technique you will use. For our case, we will be using a model called gradient boosting machines. To understand gradient boosting machines we first must understand what boosting and decision trees are. Boosting is the process of converting a weak learner into a strong learner. Decision trees are charts which help make a decision or prediction. Each branch represents a possible outcome. The end of branches represent an end result or decision.\n",
    "\n",
    "Decision trees are common in medical settings. For instance, below is an algorithm for evaluating febrile seizures. This is an example of a decision tree.\n",
    "\n",
    "<img src=\"https://img.grepmed.com/uploads/1105/febrileseizure-management-algorithm-diagnosis-complex-original.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In gradient boosting machines, we train numerous decision trees. With each training iteration, the algorithm identifies weak decision trees, and subsequently improves on these trees. This process continues until we have our final model. This final model is a curated and weighted sum of the predictions made by previous decision trees run by the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now need to split our data into training and test data. We will be splitting our data into 80% training data and 20% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:39.859783Z",
     "start_time": "2020-03-17T01:42:35.876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and test set data\n",
    "# Setting the seed value so we get the same result when we repreat\n",
    "set.seed(100)\n",
    "\n",
    "# Imputing Na w/ mice package so that our model works\n",
    "pima_diabetes <- pima_diabetes %>%\n",
    "    mutate(\n",
    "        Glucose = as.numeric(Glucose),\n",
    "        BloodPressure = as.numeric(BloodPressure),\n",
    "        SkinThickness = as.numeric(SkinThickness)\n",
    "    )\n",
    "\n",
    "suppressWarnings(mice_impute <- mice(pima_diabetes, m=1, maxit=10))\n",
    "pima_diabetes <- complete(mice_impute, 1)\n",
    "\n",
    "# Determining which rows willbe in the traiing data\n",
    "training_index <- sample(nrow(pima_diabetes), 0.8*nrow(pima_diabetes), replace = FALSE)  \n",
    "\n",
    "# Create Training Set\n",
    "training_data <- pima_diabetes[training_index,]\n",
    "\n",
    "# Create Test Set\n",
    "test_data <- pima_diabetes[-training_index,]\n",
    "\n",
    "cat('Training and Test Data Created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T03:55:52.200081Z",
     "start_time": "2019-10-24T03:55:52.180Z"
    },
    "hidden": true
   },
   "source": [
    "Now let's fit our model to the training data. We will then take a look at our model's performance using the test data and a confusion matrix.\n",
    "\n",
    "> If you're unsure what a confusion matrix is, please consult section 5.0.1 ('What is a Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:44.961207Z",
     "start_time": "2020-03-17T01:42:35.961Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "model <- (Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + bmi_interp +Insulin+ DiabetesPedigreeFunction + Age)\n",
    "\n",
    "# Add in NA action to exclude missing \n",
    "model_gbm <- suppressWarnings(train(model, data=training_data, method=\"gbm\", na.action = na.omit,verbose=FALSE))\n",
    "\n",
    "# Predict\n",
    "prediction_gbm <- predict(model_gbm, test_data[,-9])\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix(prediction_gbm, test_data$Outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we can see several useful metrics for our model. For instance, we have an `Accuracy` of 0.83, a `Sensitivity` of 0.63 and a `Specificity` of 0.91. \n",
    "\n",
    "One question you may be wondering is does our model perform well enough? That depends. That depends on the type of conditions or predictions we're making. That depends on whether alternative predictive models or tools exist and how our new model compares. Additional research or consideration should always be done consider whether a model's result is not only statistically significant, but **clinically significant**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What Is A Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A confusion matrix is a 2x2 table which computes 4 different combinations of predicted vs. actual values. The combinations are True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/320/1*Z54JgbS4DUwWSknhDCvNTQ.png\" align=\"center\" style=\"margin-bottom: 0.5em; margin-top: 0.5em;\">\n",
    "\n",
    "These 4 interpretations can be combined to generate many useful metrics. For our purpose there are three we will focus on. The first is accuracy:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\large \\text{Accuracy} = \\frac{\\large TP + TN}{\\large TP + TN + FP + FN}\n",
    "\\end{equation*}\n",
    "\n",
    "Accuracy allows us to measure how often our model predicted correctly. The second metric is sensitivity:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\large \\text{Sensitivity} = \\frac{\\large TP}{\\large TP + FN}\n",
    "\\end{equation*}\n",
    "\n",
    "Sensitivity asks the question, that when our prediction is positive (ie. in our case when a patient is predicted to be high risk) how often will the model correctly predict positively (ie. how often will the model then predict the patient to be at high risk). The final metric is specificity:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\large \\text{Specificity} = \\frac{\\large TN}{\\large FP + TN}\n",
    "\\end{equation*}\n",
    "\n",
    "Specificity asks the question, that when our prediction is negative (ie. in our case when a patient is predicted to be high risk) how often will the model correctly predict negatively (ie. how often will the model then predict the patient to be at high risk). \n",
    "\n",
    "> Note: Sometime you  may see precision and recall used instead of sensitivity and specificity. While recall is equivalent to sensitivity, precision is equivalent to something known as positive predictive value. Going into the differences is beyond this single case. Just know that these measures provide more information than accuracy alone. Precision and recall are commonly used in computer science while sensitivity and specificity are more commonly used in medicine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will be evaluating our model using a receiver operating curve (ROC) and the area under the curve (AUC) value. \n",
    "\n",
    "> If you're unsure what a ROC or AUC value is, please consult section 5.1.1 ('Understanding ROC Curves and AUC Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.197965Z",
     "start_time": "2020-03-17T01:42:36.398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a ROC curve\n",
    "ROC <- roc(response = test_data$Outcome, predictor = factor(prediction_gbm, \n",
    "                                                           ordered = TRUE))\n",
    "\n",
    "# Plot ROC with ggplot2\n",
    "plot_ROC <- ggroc(ROC)\n",
    "plot_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.222974Z",
     "start_time": "2020-03-17T01:42:36.405Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat('AUC:', round(auc(ROC), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The closer to the top left corner our ROC curve, the better. The higher our AUC value, the better. These metrics provide useful measures when tuning our model. They are also better overall measures than accuracy alone. We can compare different models using these two metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Understanding ROC Curves and AUC Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A ROC plots sensitivity (also known as the true positive rate) against 1-specificity (also known as the false positive rate). A model with a 50-50 chance of making a correct decision will have a ROC curve which is just a diagonal line. A model with a curve that hugs the top left corner is a perfect model. The area under a curve is a measure of the magnitude of the ROC curve. The closer the ROC curve is to the top left corner, the higher the AUC value. The higher the AUC value, the better. AUC value range from 0 -1. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/406/1*pk05QGzoWhCgRiiFbz-oKQ.png\" style=\"float: center; width: 34%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Explaining our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important part of any model is to explain it. We will be measuring the variable importance for our model. The higher the variable importance, the more important that variable is for predicting high risk asthma patients. This allows us to quantitatively compare which variables are more important and how much more important they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.472595Z",
     "start_time": "2020-03-17T01:42:36.854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test <- varImp(model_gbm)\n",
    "ggplot(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that `Glucose` was by far the most important variable. This makes sense since diabetes is a reflection of abnormally high blood glucose levels. What's surprising is how much of an effect that `DiabetsPedigreeFunction` has. There are two variants of diabetes, Type 1 and Type 2. Type 2 diabetes has a strong genetic component. This indicates many in our data have type 2 diabetes. Variable importance can be a good way to look for surprising results. Any surprising variables can be the subject of further investigation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You've now learned everything you need to begin testing your own models! Analytics is an iterative process and requires constantly tuning and testing different models against one another. You will now build your own model and see how it performs.\n",
    "\n",
    "One of the most decisions in model building is to decide what features/variables to include on your model. This will have a huge impact on your models performance. Run the code below to see all the features in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.505206Z",
     "start_time": "2020-03-17T01:42:37.222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:39:03.380360Z",
     "start_time": "2020-03-17T01:39:03.343Z"
    },
    "hidden": true
   },
   "source": [
    "From the list of features above, pick the features you believe are the most predictive for predicting diabetes. You can type in your features in between the brackets below. Please follow the format shown in the example below.\n",
    "\n",
    "<code>c(\"Pregnancies\",\"BloodPressure\")</code>\n",
    "\n",
    "Be careful! If there are any typo, this will not work and you will need to run the code below again with the typo corrected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:42:45.530177Z",
     "start_time": "2020-03-17T01:42:37.336Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features <- c(\"Pregnancies\",\"Glucose\",\"BloodPressure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we will see how our model performs using the features you selected. The below code will output evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T01:43:36.565022Z",
     "start_time": "2020-03-17T01:43:32.043Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Experiment with different features. As mentioned earlier, feature selection makes a huge difference in model performance. Determine which features work best and see if you can beat the model we built earlier in the case! You can rerun the <code>test_model()</code> function with new features as many times as you like. Please refer to the instructions after our variable list to see how to select new features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Congratulations! You've reached the end of the case! This case provided just one example of how analytics and healthcare can be combined to solve clinical problems. I hope your curiosity has been piqued. Data analytics will become increasingly important in healthcare as time goes on. It is a skill well worth investing in. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "414px",
    "left": "54px",
    "top": "110.8px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
